[{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"72bc358275b742659d6a427105e7e13f","permalink":"https://langcog.github.io/metalab/documentation/using_ma_data/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/using_ma_data/","section":"documentation","summary":"","tags":null,"title":"Using MetaLab Data","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"8e916914baf50ae7aee2217a1cbbabbc","permalink":"https://langcog.github.io/metalab/documentation/shinyapps/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/shinyapps/","section":"documentation","summary":"","tags":null,"title":"Applications","type":"book"},{"authors":null,"categories":null,"content":" Design Choice Analyses The research question determines many design choices in developmental research -- e.g., is the hypothesis related to the timecourse of various pressures, or merely the presence of a bias? Some methods are better suited than others for answering these different questions.\nDevelopmental curve comparison The goal for this analysis was to better understand the shape of the developmental curve. To do this we used linear mixed effects models, so that the variance of individual meta-analyses could be accounted for.\nHierarchical Random Effects in Meta-Analyses: Do they change stuff? Here we explore whether and how accounting for this possible correlation affects both a random effects base model and a moderator analysis.\n","date":1679961600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1679961600,"objectID":"4eb8956b6c83092ba44af1f51228c298","permalink":"https://langcog.github.io/metalab/report/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/report/","section":"report","summary":"Design Choice Analyses The research question determines many design choices in developmental research -- e.g., is the hypothesis related to the timecourse of various pressures, or merely the presence of a bias? Some methods are better suited than others for answering these different questions.\nDevelopmental curve comparison The goal for this analysis was to better understand the shape of the developmental curve. To do this we used linear mixed effects models, so that the variance of individual meta-analyses could be accounted for.","tags":null,"title":"Reports","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"e32c86abad76fb25961f561a45726be3","permalink":"https://langcog.github.io/metalab/documentation/rpackage/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/rpackage/","section":"documentation","summary":"","tags":null,"title":"Building the Metalab Platform","type":"book"},{"authors":null,"categories":null,"content":" Welcome to MetaLab, we provide interactive tools for community-augmented meta-analysis, power analysis, and experimental planning in cognitive development research.\n","date":1595721600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1595721600,"objectID":"5e4b1544ca569c05660a1b33d29abb2f","permalink":"https://langcog.github.io/metalab/documentation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/","section":"documentation","summary":"Welcome to MetaLab, we provide interactive tools for community-augmented meta-analysis, power analysis, and experimental planning in cognitive development research.","tags":null,"title":"Welcome","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa8269ee5d5d91ce603497dd36a82a8c","permalink":"https://langcog.github.io/metalab/people/alejandrina/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/alejandrina/","section":"people","summary":"alecristia@gmail.com https://sites.google.com/site/acrsta/ École Normale Supérieure","tags":null,"title":"Alejandrina Cristia","type":"governingboard"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"56aa5e925fee3a39ca2714bacc19d6d0","permalink":"https://langcog.github.io/metalab/people/angeline/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/angeline/","section":"people","summary":"atsui029@uottawa.ca University of Ottawa","tags":null,"title":"Angeline Tsui","type":"curator"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"730fe5da8e8ea9a1ea4d9bb39f875171","permalink":"https://langcog.github.io/metalab/people/cecile/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/cecile/","section":"people","summary":"cecile.issard@gmail.com École Normale Supérieure","tags":null,"title":"Cécile Issard","type":"curator"},{"authors":null,"categories":null,"content":"chbergma@gmail.com https://sites.google.com/site/chbergma/ Max Planck Institute for Psycholinguistics ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2889a58cda4ff8d24f663350db885796","permalink":"https://langcog.github.io/metalab/people/christina/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/christina/","section":"people","summary":"chbergma@gmail.com https://sites.google.com/site/chbergma/ Osnabrück University of Applied Sciences and Max Planck Institute for Psycholinguistics","tags":null,"title":"Christina Bergmann","type":"leader"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"eb5331dbfc1edcf32f6d65cec49cef07","permalink":"https://langcog.github.io/metalab/people/fleur/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/fleur/","section":"people","summary":"f.m.h.g.vissers@gmail.com Tilburg University","tags":null,"title":"Fleur Vissers","type":"curator"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5899a02620cadf81d8f75239c69645e5","permalink":"https://langcog.github.io/metalab/people/francesco/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/francesco/","section":"people","summary":"francesco.margoni@unitn.it Università di Trento","tags":null,"title":"Francesco Margoni","type":"curator"},{"authors":null,"categories":null,"content":"MetaLab has many features and ways to access information and even contribute. The menu on the left lets you navigate the existing documentation, if questions remain, please get in touch!\nNote This page is under revision, access the previous tutorial here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa094c77936825fab50597a2b0535504","permalink":"https://langcog.github.io/metalab/documentation/getting-started/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/getting-started/","section":"documentation","summary":"Entry to documentation","tags":null,"title":"Getting Started","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7202066667fae97c211b1318c08551bd","permalink":"https://langcog.github.io/metalab/people/hugh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/hugh/","section":"people","summary":"hugh.rabagliati@ed.ac.uk University of Edinburgh http://www.psy.ed.ac.uk/homepages/the-rab-lab/","tags":null,"title":"Hugh Rabagliati","type":"curator"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e5d275d17a549943bd7d32ff74ee37a7","permalink":"https://langcog.github.io/metalab/people/julia/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/julia/","section":"people","summary":"carbajalmjulia@gmail.com https://github.com/juliacarbajal École Normale Supérieure","tags":null,"title":"Julia Carbajal","type":"formermember"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b716c63bc7363702cd5ba57131958671","permalink":"https://langcog.github.io/metalab/people/katie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/katie/","section":"people","summary":"katie.m.vonholzen@gmail.com https://kvonholzen.github.io/ Technical University of Dortmund","tags":null,"title":"Katie Von Holzen","type":"curator"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1b037d7eb189f3250cef0e597335e67","permalink":"https://langcog.github.io/metalab/people/michael/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/michael/","section":"people","summary":"mcfrank@stanford.edu http://web.stanford.edu/~mcfrank/ Stanford University","tags":null,"title":"Michael C. Frank","type":"governingboard"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"98765bfb88594db61d95c06860ebe0ce","permalink":"https://langcog.github.io/metalab/people/mika/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/mika/","section":"people","summary":"mika.br@gmail.com http://mikabr.github.io/ Stanford University","tags":null,"title":"Mika Braginsky","type":"formermember"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"da326796900368b4c401013dc9df48b1","permalink":"https://langcog.github.io/metalab/people/molly/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/molly/","section":"people","summary":"mollyllewis@gmail.com http://home.uchicago.edu/~mollylewis/ University of Chicago/University of Wisconsin-Madison","tags":null,"title":"Molly Lewis","type":"governingboard"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"18097fe1fbe68e7cc7e96141331c01ec","permalink":"https://langcog.github.io/metalab/people/page/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/page/","section":"people","summary":"page.piccinini@gmail.com http://idiom.ucsd.edu/~ppiccinini/ École Normale Supérieure","tags":null,"title":"Page Piccinini","type":"formermember"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a54de55e39d4e0fa285de008842a00bb","permalink":"https://langcog.github.io/metalab/people/rodrigo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/rodrigo/","section":"people","summary":"dalbenwork@gmail.com Concordia University","tags":null,"title":"Rodrigo Dal Ben","type":"curator"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2370e82131c0cc0e90b344a232fed815","permalink":"https://langcog.github.io/metalab/people/sara/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/sara/","section":"people","summary":"selshawa96@gmail.com https://saraelshawa.com/","tags":null,"title":"Sara El-Shawa","type":"team"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"35e7e40773e986ce31676b2618c6ace4","permalink":"https://langcog.github.io/metalab/people/sho/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/sho/","section":"people","summary":"tsujish@gmail.com https://sites.google.com/site/tsujish/ The University of Tokyo","tags":null,"title":"Sho Tsuji","type":"leader"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"835f996da527f5c5baadecf5a4d8686f","permalink":"https://langcog.github.io/metalab/people/alessandro/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/alessandro/","section":"people","summary":"sanchez7@stanford.edu https://github.com/amsan7 Stanford University","tags":null,"title":"Alessandro Sanchez","type":"formermember"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3a98a4b6d0a8ca4dc7c2b3aaffcbef5f","permalink":"https://langcog.github.io/metalab/people/loretta/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/loretta/","section":"people","summary":"gasparini.lorett@gmail.com Murdoch Children's Research Institute","tags":null,"title":"Loretta Gasparini","type":"team"},{"authors":null,"categories":null,"content":" Contribution Challenge 2020 Winners The 2020 contribution challenge has closed and we received a record number of 9 submissions, thanks to all who joined and to the Fetzer Franklin Fund for their support. We are working on making the data available on MetaLab.\nThe three winners are:\nGabrielle Strouse (University of South Dakota) with a meta-analysis on whether infants learn from video just as well as from live interaction, and the results are already published: doi.org/10.1111/cdev.13429\nZ. L. Zhou (UCLA) with a meta-analysis on the time course of native-language phonotactic learning; stay tuned for a full paper.\nLoretta Gasparini (European Master’s in Clinical Linguistics+) on infants’ preference for their native language and ability to discriminate between languages and accents, a preprint is available here: doi.org/10.31219/osf.io/rmn5x\nThe Contribution Challenge 2020 Call To celebrate the latest (ongoing) upgrade and the inclusion of 25 meta-analyses to date, the MetaLab team with support of the Fetzer Franklin Fund is organizing a challenge for authors of meta-analyses on cognitive development (data challenge) and for contributors of shiny apps (code challenge). The contribution challenge will offer three $1,000 US in cash prizes distributed between (teams of) authors or coders, who contribute meta-analysis data to the MetaLab database or, who make substantial contributions to the site, for example proposing and implementing a shiny app providing a new analysis or functionality in coordination with the MetaLab team. Deadline is 2020-10-15 (15 October). You can find more information here: https://bit.ly/MetaLabChallenge2020\nContribution Challenge 2018 Winners The MetaLab challenge calling for meta-analyses on cognitive development, with support from Berkeley Initiative for Transparency in the Social Sciences (BITSS), has closed. We received data for 7 meta-analyses, which will be added to MetaLab in the coming months.\nThe winners are three early career researchers: Angeline Tsui (Ottawa / Stanford), M. Julia Carbajal (LSCP Paris), and Katie Von Holzen (LPP Paris / Maryland).\nAngeline Tsui contributed data on a meta-analysis of the “Switch Task”, a key paradigm in language acquisition research. In a switch task infants are taught new labels for unknown objects (such as “lif” vs “neem”). Their knowledge is then tested by whether they can detect the switching of the word-object pairings (calling the “lif” now “neem”). Results from switch task studies raised the possibility that there are differences in infants’ abilities to distinguish speech sounds in a pure speech perception task (where no visual information giving cues to the referent is presented) versus in a word learning context, and led to a string of follow-up studies that are synthesized in this meta-analysis. Angeline’s paper describing the meta-analysis in more detail is currently under review in Developmental Psychology (Preprint).\nM. Julia Carbajal conducted a meta-analysis on infants’ ability to distinguish frequent from rare words (like “hello” versus “hallux”) when these words are just presented via a speech stream without visual referents. In this type of studies, researchers typically compare how long infants like to listen to different word lists (one with very frequent and one with very rare words), which is an easy to apply but very indirect measure. Studies on infants’ ability to distinguish those word lists were the first to establish when infants begin to systematically learn words in their native language, albeit with varying results across studies. It was thus a good moment to estimate the meta-analytic effect size. The paper on this meta-analysis is currently in preparation.\nKatie Von Holzen’s meta-analysis (conducted in collaboration with MetaLab team member Christina Bergmann, which led to 50% of her data being discounted) addresses infants’ sensitivity to mispronunciations (for example, whether “tog” is a good label for “dog”). Dealing with mispronunciations is another key skill in language acquisition and processing, and the meta-analysis aims to show whether infants become more strict or more lenient with experience as to how a word should sound. A short report on the meta-analysis is appearing in the Proceedings of the Cognitive Science Society Conference (Preprint), a full-length paper is in preparation.\nWe would also like to specifically highlight the contribution of Hugh Rabagliati, Brock Ferguson, and Casey Lew-Williams, who would have been among the winners based on their contribution, but generously stepped down to leave the prize for an early career researcher. The meta-analysis they contributed addresses how infants can learn rules that are implicit in their environment. Their open access paper just appeared in the journal Developmental Science (Rabagliati, H., Ferguson, B., \u0026amp; Lew-Williams, C. (2018). “The profile of abstract rule learning in infancy: Meta-analytic and experimental evidence”. Developmental Science, DOI: 10.1111/desc.12704).\nThank you to everyone who participated in our challenge. MetaLab continues to be open for submissions, we provide further information on the Tutorials page.\nData-sharing policy Meta-analyses will be added to the MetaLab online database. Users will be able to download your data and potentially re-use it. However, MetaLab requires anyone who uses a dataset to cite the contributors of the dataset, even if there is no publication or pre-print yet. Citation that users should use are available in the documentation of each dataset, potentially specifying « in preparation », and/or linking to an online repository (such as OSF). Note that we will update these entries as preprints and published papers become available. Learn more by reading our full citation policy. Unpublished meta-analyses shared on MetaLab do not count as publication.\nMetaLab is dynamic: Meta-analysis can be updated, adding new relevant studies when they are published. Contributors can retain control on this for as long as they want to. Two options exists for the curation and review of data. Contributors can choose to be the curator. This means a contributor agrees to be the person responsible for identifying new relevant papers and signaling them to the MetaLab data manager, who will add them to the database. Curators are expected to check the data entered regularly. Curators are part of the MetaLab team and can choose to join discussions regarding e.g. site revamping. Alternatively, contributors can choose to step down completely, and it will be MetaLab’s job to assign a new curator for such a dataset.\n","date":1595721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595721600,"objectID":"0b698d2f7d44683c9822cab4db94082a","permalink":"https://langcog.github.io/metalab/documentation/challenge/","publishdate":"2020-07-26T00:00:00Z","relpermalink":"/documentation/challenge/","section":"documentation","summary":"Contribution Challenge 2020 Winners The 2020 contribution challenge has closed and we received a record number of 9 submissions, thanks to all who joined and to the Fetzer Franklin Fund for their support. We are working on making the data available on MetaLab.\nThe three winners are:\nGabrielle Strouse (University of South Dakota) with a meta-analysis on whether infants learn from video just as well as from live interaction, and the results are already published: doi.","tags":null,"title":"Contribution Challenge","type":"book"},{"authors":null,"categories":null,"content":" This page is under revision, access the previous tutorial here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"83eadbf6287db7b4b054d30b5dae6394","permalink":"https://langcog.github.io/metalab/documentation/faq/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/faq/","section":"documentation","summary":"Troubleshoot common issues.","tags":null,"title":"FAQ","type":"book"},{"authors":null,"categories":null,"content":" Why conduct a meta-analysis (MA)? For a quick overview on what are meta-analysis (MA), please watch this 3-minute video:\nMeta-analyses (MAs) can be useful several purposes, including: (1) theory building and evaluation and (2) practical decisions during study design. This section starts with some basics on why MAs are more useful than single studies for those two purposes.\nWhy are single studies not enough? When thinking about development, we often look at published experiments testing whether infants have specific abilities, for example whether infants treat native vowels differently from non-native ones, and how those abilities change with age (for more details on this specific topic see [here] (/dataset/inphondb-native.html).\nThe results of a single experiment cannot answer those questions once and for all: Each experiment measures behavior of a set of infants in a very specific situation, which might not be generalizable to other situations. Moreover, there might be a measurement error in this one-time snapshot of reality. Finally, the literature likely contains some false positives and false negatives, simply due to the way we conduct statistics. With a significance threshold alpha set to .05, every study we run has a 5% chance of telling us that infants can do something when this is not true - this is a false positive. This likelihood becomes bigger when researchers engage in seemingly innocent and possibly common practices that increase the chance of a false positive, such as running multiple analyses until one is significant. Some people even propose that most published literature consists of false positives! With a beta set to .2, every study we run has a 20% chance of telling us that infants cannot do something when they actually can - this is a false negative. In fact, many studies are underpowered, meaning they test too few participants, so that a non-significant result is not due to a true lack of effect, but rather to lack of power to detect it. None of these necessarily are due to bad intentions, wrongdoing, or even poor research practices. Reality is complex and thus any one study can only give us a single, noisy estimate.\nHow can MAs help? MAs may be the cheapest way to assess generalizability and test whether a certain factor matters. Instead of running 10 experiments, 1 on each vowel contrast, we collect 10 studies in the literature into a single analysis! If effects for e.g. native versus non-native vowels differ significantly in the literature as a whole, then we can be more confident that results will generalize to unobserved vowel contrasts.\nMAs are therefore a tool to collaborate across space and time, instead of having one lab invest a lot of resources. This has the automatic benefit that MAs often also cover more varied participant populations than a single study usually can (for notable exceptions, see for example the ManyBabies Studies.\nHow can MAs help with false positives? Collecting many study results from different researchers is a way to try and make up for the possibility that biases influenced the outcome. We can even use MAs to check for biases, such as asking whether a suspicious number of p-values is just below the significance threshold or whether results are systematically skewed in one direction. Why biases matter is wonderfully illustrated here: http://www.alltrials.net/news/the-economist-publication-bias/. Checking for biased results is a whole literature on its own, but as a start tools such as p-curving apps are easily available for every researcher. http://www.p-curve.com/ or http://shinyapps.org/apps/p-checker/ are two well-documented examples.\nHow can MAs help with false negatives? MAs help in three ways. By pooling data together, we may be able to bring out a small effect that was too difficult to detect.\nAdditionally, we often do not know about these non-significant findings because it is quite difficult to publish them. Community-augmented MAs like those in MetaLab provide a home for unpublished results, and allow researchers to benefit from the experience of others.\nFinally, MAs help us in experiment design so we can avoid false negatives due to low power. When the size of an effect is known and with a fixed significance threshold, calculating power is straightforward. Here is a simulation of how all ingredients fit together: \u0026lt;rpsychologist.com/d3/NHST/\u0026gt;.\nCan MAs help in other ways? The MAs in MetaLab can also help with study design, because often many design variables have been coded. Examples include the stimuli used, how long trials were, etc. Instead of doing a tiresome literature review, you can find out what is the most common procedure or which is associated with the biggest effect.\n","date":1595721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595721600,"objectID":"02598c8732e7cf820ff38dd84dafcfcf","permalink":"https://langcog.github.io/metalab/documentation/why_do_a_ma/","publishdate":"2020-07-26T00:00:00Z","relpermalink":"/documentation/why_do_a_ma/","section":"documentation","summary":"Why conduct a meta-analysis (MA)? For a quick overview on what are meta-analysis (MA), please watch this 3-minute video:\nMeta-analyses (MAs) can be useful several purposes, including: (1) theory building and evaluation and (2) practical decisions during study design. This section starts with some basics on why MAs are more useful than single studies for those two purposes.\nWhy are single studies not enough? When thinking about development, we often look at published experiments testing whether infants have specific abilities, for example whether infants treat native vowels differently from non-native ones, and how those abilities change with age (for more details on this specific topic see [here] (/dataset/inphondb-native.","tags":null,"title":"Why Meta-Analysis?","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"408e3dc13d1d78e5ca83d9a2216695c0","permalink":"https://langcog.github.io/metalab/people/erik/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/erik/","section":"people","summary":"erikriverson@gmail.com https://github.com/erikriverson ","tags":null,"title":"Erik Iverson","type":"team"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e7169a19492ad55d67d3edec6c364c81","permalink":"https://langcog.github.io/metalab/people/priya/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/priya/","section":"people","summary":"priyasilverstein@gmail.com https://priyasilverstein.wixsite.com/website ","tags":null,"title":"Priya Silverstein","type":"curator"},{"authors":null,"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3832ffb21ffc479c013d0a22e1404410","permalink":"https://langcog.github.io/metalab/app/visualization/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/app/visualization/","section":"app","summary":"Explore a variety of interactive charts driven by the MetaLab database by your datasets and moderators","tags":null,"title":"Visualization","type":"shinyapp"},{"authors":null,"categories":null,"content":" Build a MA Choosing the right MA question How do I define my MA question? Choose the appropriate level of detail for your MA topic. The topic of your meta-analysis should be broader than the one of a single experiment (e.g. “How do babies segment words of different stress patterns?”), but narrower than a whole research field (e.g. “How do babies learn language?”). The goal is to be able to gather comparable papers, measuring consistant dependant variables, to allow you to compute a common statistical metric (i.e. effect size) from them.\nDefine your population of interest precisely. Homogeneous can mean many things; age, language, typical versus atypical. You may run a meta-analysis where you accept many different levels for some of the variables and see how it affects results, defining them as MA moderators, for example seeing if effects are consistent across ages. There should still be some unifying element in your studies though so you have one broad result of your meta-analysis.\nConsider the number of available studies on your topic. Your MA topic also depends on how many studies have been done on it. If you want to run a simple comparative MA, as few as two studies could be okay. But if you want to run an analysis with a lot of moderators, 5 studies probably isn’t enough to warrant a meta-analysis.\nWhy should I bother keeping track of the MA creation process? It is important that you build traceability of your work from the start, particularly since in larger MAs other people may finish up the work or you want to check later on why you decided to exclude a given paper. So to make sure that all of your decisions are recorded and clear, make a copy of this decision spreadsheet. Don’t forget to rename it, to give us a “viewing” link, and clean it up as follows.\nStep 1: Click on “File” and select the “Make a copy…” option\nStep 2: In the window that appears, change the name to something like “MA_TOPIC”\nStep 3: Click on the blue button “Share” on the top right.\nStep 4: In the menu, click on “Get shareable link” on the top right\nStep 5: Copy the link and send it to us.\nStep 6: Clean up\nThe model spreadsheet contains some fake entries and notes. Our recommendation is, so as not to get confused, to remove the instructions found on the top lines of each sheet and the fake information that is already entered - except for a couple of exceptions: the pink columns (A, B and W) in the Relevant_studies_search sheet contain formulas that may be useful to you. So you might want to delete the contents of the other columns and keep those two in order to reuse the formulas.\n************\nAdditionally, make a copy of this flowchart, rename and share as you did for your spreadsheet above. This figure gives you an overview of the process, and you will be filling in the boxes with the right numbers as you go along so that people who continue this MA and/or those interested in assessing this work can make sure that you followed the procedure.\nNow that I have my list of related studies, how do I set my inclusion criteria? Probably not. In this step, you will go through the initial list you put together in step 2, and make decisions to include/exclude papers, mostly based on the abstract. In addition to creating your sample for data entry (step 4) you will start honing your inclusion criteria. Typically, these will include:\na homogeneous scientific question: \u0026gt; Make sure you have clearly \u0026gt; defined the purview of e.g. cross-situational learning (e.g., this \u0026gt; name itself is vague to those outside the domain, so define it in \u0026gt; a more specific way: “exposure to sets of images paired with \u0026gt; wordforms with the goal of studying word-form image association, \u0026gt; but crucially multiple images are shown at once (unlike e.g. the \u0026gt; switch procedure)”)\na homogeneous infant population: \u0026gt; Typically-developing children, \u0026gt; between the ages of XX and YY (the precise ages may stem from your \u0026gt; seminal paper; perhaps to start with, you could set the maximum to \u0026gt; 36 months, the minimum to 0 months); consider whether you also \u0026gt; need to restrict the sample based on infants’ native language on \u0026gt; theoretical reasons\nThe last one is perhaps the trickiest. Staying close to your seminal paper will allow you to reduce the amount of variation in your sample due to methodological “details”, and to make it easier for yourself to enter data, because all the results will be structured in similar ways. But it’s important to know that this is a potential source of bias. For instance, you could decide that you will only input data using a specific kind of artificial language because you know that papers not using this language have smaller effects. This will end up being a self-confirmation exercise – unless there are a priori strong theoretical reasons to exclude other kinds of language or to assume that the learning mechanisms attributed to the infant cannot be generalized to these other languages.\nEvery time you make a decision regarding these and other key criteria, remember to note it in your decision spreadsheet, in the last sheet called “Notes_inclusion”. For example, mine looks like this:\nQuestion Decision Date a homogeneous scientific question learning of speech sound categories, where the categories are represented by a multimodal versus unimodal distribution of acoustic correlates 10/19/2015 a homogeneous infant population typically-developing children, between the ages of 0 and 36 months 10/19/2015 a homogeneous procedure passive exposure in the lab, testing via any behavioral or non-behavioral method 10/19/2015 Selecting Studies How do I select the studies to include? The goal of this step is to put together a list of publications that you will look at and consider for inclusion. In a typical MA, you make the most comprehensive list possible in order to answer a specific research question and/or to cover a given phenomenon. This typically means going through 1,000 abstracts, and reading in full 100 papers. You can start with the seminal paper for your effect of interest, and then look for the studies citing your seminal one. Use pubmed’s search to find your pivot study’s entry, for instance by copy-pasting the full paper title in the builder:\nWhen you press “search”, usually you’ll find the entry for your seminal paper (or if the title was not unique, you might need to click on one of the entries found until you do come across the entry for your seminal paper). Notice on the right a section entitled “Cited by …” Scroll down to click on the link at the bottom of this section stating “See all..”\nYou will now see all studies citing your seminal one. Constrain it further by clicking on “Show additional filters” on the left, and checking the box for “Infant: birth to 23 months”:\nYou now want to save all these papers in your reference management software. If you use Zotero: Click on the drawing of a folder in your status/search bar. When you do so, a window will pop up with all the results for that pubmed page:\nClick on “select all” and “OK”. Repeat for the other search pages. This will store the citation information, including abstract, in zotero.\nYou can also interrogate Pubmed with a script, such as the one we have prepared.\nHow exactly can I go about looking through my initial list and making decisions? What if the title and abstract doesn’t allow me to decide?\nThen play it safe and include the paper to check based on the full text.\nWhat if the title and abstract doesn’t allow me to decide, but in fact I know the paper and I know it needs to be excluded?\nThen you probably have already seen the full text of the paper, so say “yes” for the screening decision, and then “no” for the full-text decision.\nHow many papers should I enter? Ideally, you would enter everything: published or unpublished, proceedings or journal, etc. However, sometimes you may want to start a “seed” meta-analysis that just gives a rough idea of an area.\nIn this case, how large should your sample be? Mika and Molly have done some simulations to help you decide. By and large, it looks like the more, the better – clearly estimates get more precise (confidence intervals narrow) as more papers are entered. Based on this information, we are proposing a minimum of 10 included experiments as a pragmatic first step, knowing that your estimate is not very precise.\nHow should I structure the data for my MA? We are hoping that eventually all of these MAs may be included in MetaLab, so we ask you to use the MA template (create a copy, as you did in step 1), and follow the field specifications. Ideally, you would code all potentially relevant moderator variables (e.g., experimental manipulations) in addition to the core characteristics (columns in red; e.g. means). However, in the interest of time, you can get started with the core characteristics only. Remember once more to give us viewing rights (see step 1 for instructions).\nWhat are the relevant variables for a MA, and how many input rows/columns should I make? Here are some FAQs we have received on this:\nOne of my papers has a single experiment but involves both Spanish and English speakers who are tested on a native and a nonnative speech sound contrast. Should that count as 4 experiments (2 languages x 2 contrasts)?\nHow many rows you make depends on how the results are reported. In this case, the authors report the outcome separately for all four groups. Therefore, please enter the four groups separately; each into their own row. You can copy over descriptions of the experiment.\nIn Experiment 1, there are two age groups. Do I have to report the age for both groups or do I average both groups into one? If I have to report both groups, how do I report this in the input form?\nHow many rows you make depends on how the results are reported. In this case, the authors report an average outcome over both age groups, since they did not find a significant difference between the two groups. Therefore, please enter only one row and calculate the average age. If the results were reported separately per age group, make a\nHow do I retrieve studies? In a typical full MA, you go through the whole list and only then start entering. The procedure is as follows. Go back to your spreadsheet, and for each study that has been decided as a “yes” during screening, try to retrieve the full text for the paper as you normally would (e.g., search through scholar.google.com; regular google; your institution’s library, etc.) If you cannot retrieve it, update your spreadsheet sheet Relevant_studies_search to mark this paper as “no” in column F entitled “Fulltext_retrieved”. If you want, you can contact the authors to try to get the full text from them, in which case you can note this on column G.\nIf you do find the full text, go through the paper to find the first experiment reported. You will enter all experiments and conditions one at a time, and fill in their information in the MA spreadsheet you created in step 4. ### How do I enter and code relevant studies?\nIMPORTANT: You should work backwards from the results section: look at what dependent measures are reported fully enough that you will be able to extract an effect size from them.\nThe following information allows one to calculate an effect size (we are sticking to experimental designs, since most of our MAs are experimental):\nbetween-participant studies: \u0026gt; Means and SDs (not SEs!) of the \u0026gt; dependent variable for each infant group** are all that is \u0026gt; required for the calculation of Cohen’s d. Sometimes, means and \u0026gt; SDs are not available as numbers. If there are clear figures, you \u0026gt; can try to estimate means and SDs using** this online \u0026gt; app*. If you decide to \u0026gt; estimate values from figures, add a column to keep track of this. \u0026gt; Finally, t or F values for the main effect in combination with \u0026gt; sample sizes can be used to calculate Cohen’s d. Note them \u0026gt; when available.\nwithin-participant studies: \u0026gt; Effect sizes for this type of \u0026gt; study are calculated the same way as in between-participant \u0026gt; studies, but in order to calculate the weight of these studies \u0026gt; the correlation between the first and second measurements is \u0026gt; required (to account for the amount of \u0026gt; within-participant variation). Since this measure is usually not \u0026gt; reported, we provide below median and range for correlations found \u0026gt; in existing MAs.\nInfant word segmentation from native speech: 0.641 (range: 0.140 to 0.921)\nInfant vowel discrimination (native and nonnative): 0.496 (range: -0.413 to 0.855)\nen entering papers, please remember a key thing: all analyses are done by machines, and machines cannot read text! So if a column is “numeric”, please do not enter things that aren’t numbers (such as text, spaces, ~, etc). This is particularly important for the dependent measures!\nAt this stage, you might find that a given paper does not contain the right information for being included. In this case, you can and should exclude it. If you have already started entering it, you can leave the information you entered and put in “comments” that the entry is incomplete (although if you followed our advice above, you won’t have wasted time entering it!). Remember to update your spreadsheet with each paper you read and made a decision on.\nThe article I enter has 3 experiments, and the first is with adult participants. Do I need to enter this experiment?\nNo, please only enter the infant/child experiments\nWhat level of detail should I report? The sound stimuli differ approx. 6 ms in length, but the experiment is not about length differences. Do I have to report this difference although it is very small?\nIn case there’s a column for stimulus length, please report it. You are right that this experiment is not about length differences, but having the information cannot hurt, and eventual analyses will reflect that the difference is very small.\nThe article reports a table with the lengths of each individual stimulus. Should I calculate and report the average value?\nYes, please report the averaged value in the appropriate column.\nI am entering an article with the HAS method. The authors report results for both the 2 and 4 minutes after the test phase has started. Your example only reports the results after 2 minutes, but would you still want me to report both?\nIt is often the case that articles report more than one type of result. Please just report the ones that we also provide in the example file!\nEffect Sizes What are effect sizes? In MAs (meta-analyses) we express the outcome of a single experiment in a way that captures how big an effect is and how much it varies. There are 3 groups of effect sizes:\n1. effect sizes based on means, which includes Cohen’s d on which we focus from here on;\n2. effect sizes based on binary data; and\n3. effect sizes based on correlations.\nSince most developmental studies in the lab use mean responses of two groups or of the same infant in two (or more) conditions, Cohen’s d is the appropriate effect size measure. This chapter 3 and the following ones provide a gentle introduction to effect sizes. Cohen’s d is based on standardized mean differences. To get a feel for Cohen’s d we highly recommend to play with the visualization of RPsychologist. A list of recommended readings is also provided at the end of this document.\nIn a typical infant study, babies might hear two types of trials and the responses to each are compared. In most papers, it is sufficient that the difference between the trial types reaches statistical significance, but in a meta-analyses we care about the size of this single observed effect and its variance. This allows us to pool over several studies, weigh each datapoint, and arrive at an estimate of the underlying, true effect. This then allows us to calculate power and check how effect sizes might be systematically affected by variables such as infant age in “moderator analyses”.\nRecommended further readings for an introduction to effect sizes:\nTextbooks are great to get a basic overview of how to calculate effect sizes. We consulted: Lipsey, M. W. \u0026amp; Wilson, D. B. (2001). Practical meta-analysis. Thousand Oaks, CA: Sage.\nA great primer and a spreadsheet document to calculate effect sizes by hand can be found via: D. Lakens. (2013). Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-tests and ANOVAs . Frontiers in Psychology 4:863. Materials on OSF\nSince textbooks do not cover every possible question that different meta-analysts may encounter, we turned to articles for more specific questions. We found this article useful for considering the comparability of effect sizes from within- and between-participant designs: Morris, S. B., \u0026amp; DeShon, R. P. (2002). Combining Effect Size Estimates in Meta-Analysis With Repeated Measures and Independent-Groups Designs. Psychological Methods, 7(1), 1805-125. doi: 10.1037//1082-989X.7.1.105\nBorenstein, M., Hedges, L. V. ,Higgins, J. P. T., Rothstein, H. R. (2009). Introduction to Meta-Analysis. John Wiley \u0026amp; Sons. DOI: 10.1002/9780470743386.ch3 How do I calculate Effect Sizes? We use R to calculate effect sizes. Visit https://github.com/langcog/metalab2/tree/master/scripts for our code. The metafor package also includes functions to compute the observed effect sizes.\nWe recommend the following for an introduction to effect sizes:\nTextbooks are great to get a basic overview of how to calculate effect sizes. We consulted: Lipsey, M. W. \u0026amp; Wilson, D. B. (2001). Practical meta-analysis. Thousand Oaks, CA: Sage.\nA great primer and a spreadsheet document to calculate effect sizes by hand can be found via: D. Lakens. (2013). Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-tests and ANOVAs . Frontiers in Psychology 4:863. Materials on OSF\nSince textbooks do not cover every possible question that different meta-analysts may encounter, we turned to articles for more specific questions. We found this article useful for considering the comparability of effect sizes from within- and between-participant designs: Morris, S. B., \u0026amp; DeShon, R. P. (2002). Combining Effect Size Estimates in Meta-Analysis With Repeated Measures and Independent-Groups Designs. Psychological Methods, 7(1), 1805-125. doi: 10.1037//1082-989X.7.1.105\nWhat if I don’t have all the required information? Two groups of infants are tested and I treat them as two different entries, but the number of included and excluded infants are only reported as a whole over both groups. What do I do?\nAs the best approximation we can get, please divide the reported number through the number of groups (in your case 2).\nThe age of infants is reported in weeks, therefore I multiplied it with 7 to convert it into days. I read in your instructions that you have to multiply months with 30.42 to get a proxy for days. So my question is whether I have to multiply with a different number than 7 to get a proxy for days?\nNo, that’s fine the way you did it!\nIn some cases you will still need to contact the authors of the study. People probably don’t know you, so think about what in the object would make you open an email from a stranger. Something like “including your paper in a MA” should be motivational. People are busy: they don’t have time to read lengthy email, especially from someone they don’t know, so be as concise as possible. You could still give them more details later if they ask for it. Don’t be shy, authors are likely to be happy to hear that someone is interested in their work and is going to cite them!\nHow to run a meta-analytic regression ? Are there some MA specific plots that I should make? Resources MA template\nCoding book\nInterrogating PubMed via a script\nSelecting for inclusion\nExample MAs: InWordDB\nInstructions for creating a CAMA (including further resources)\nStructure for MA How should I structure the data for my meta-analysis? We are hoping that eventually all of your MAs (meta-analyses) will be included in MetaLab, so we ask you to use the MA template (create a copy), and follow the field specifications to ensure compatibility. (Note that right now, winter 2018, these specifications are biased towards language acquisition research. If you work on another topic, we would be thrilled if you helped us expand and adapt MetaLab).\nIdeally, you would code all potentially relevant moderator variables (e.g., experimental manipulations) in addition to the core characteristics (columns in red; e.g., number of participants). However, in the interest of time, you can get started with the core characteristics only. Remember once more to give us viewing rights.\nWhat are the relevant variables for a MA, and how many input rows/columns should I make? One of my papers has a single experiment but involves both Spanish and English speakers who are tested on a native and a nonnative speech sound contrast. Should that count as 4 experiments (2 languages x 2 contrasts)?\nHow many rows you make depends on how the results are reported. In this case, the authors report the outcome separately for all four groups. Therefore, please enter the four groups separately; each into their own row. You can copy over descriptions of the experiment.\nIn Experiment 1, there are two age groups. Do I have to report the age for both groups or do I average both groups into one? If I have to report both groups, how do I report this in the input form?\nHow many rows you make depends on how the results are reported. In this case, the authors report an average outcome over both age groups, since they did not find a significant difference between the two groups. Therefore, please enter only one row and calculate the average age. If the results were reported separately per age group, make a\nHow do I retrieve studies? In a typical full MA, you go through the whole list and only then start entering. The procedure is as follows. Go back to your spreadsheet, and for each study that has been decided as a “yes” during screening, try to retrieve the full text for the paper as you normally would (e.g., search through scholar.google.com; regular google; your institution’s library, etc.) If you cannot retrieve it, update your spreadsheet sheet Relevant_studies_search to mark this paper as “no” in column F entitled “Fulltext_retrieved”. If you want, you can contact the authors to try to get the full text from them, in which case you can note this on column G.\nIf you do find the full text, go through the paper to find the first experiment reported. You will enter all experiments and conditions one at a time, and fill in their information in the MA spreadsheet you created in step 4.\nHow do I enter and code relevant studies? IMPORTANT: You should work backwards from the results section: look at what dependent measures are reported fully enough that you will be able to extract an effect size from them.\nThe following information allows one to calculate an effect size (we are sticking to experimental designs, since most of our MAs are experimental):\nbetween-participant studies:\n\u0026gt; Means and SDs (not SEs!) of the dependent variable for each infant group are all that is required for the calculation of Cohen’s d. Sometimes, means and SDs are not available as numbers. If there are clear figures, you can try to estimate means and SDs using this online app or the R package metaDigitise. If you decide to estimate values from figures, add a column to keep track of this. Finally, t or F values for the main effect in combination with sample sizes can be used to calculate Cohen’s d. Note them when available.\nwithin-participant studies:\n\u0026gt; Effect sizes for this type of study are calculated the same way as in between-participant studies, but in order to calculate the weight of these studies the correlation between the first and second measurements is required (to account for the amount of within-participant variation). Since this measure is usually not reported, we provide below median and range for correlations found in existing MAs.\nInfant word segmentation from native speech: 0.641 (range: 0.140 to 0.921)\nInfant vowel discrimination (native and nonnative): 0.496 (range: -0.413 to 0.855)\nWhen entering papers, please remember a key thing: all analyses are done by machines, and machines cannot read text! So if a column is “numeric”, please do not enter things that aren’t numbers (such as text, spaces, ~, etc). This is particularly important for the dependent measures!\nAt this stage, you might find that a given paper does not contain the right information for being included. In this case, you can and should exclude it. If you have already started entering it, you can leave the information you entered and put in “comments” that the entry is incomplete (although if you followed our advice above, you won’t have wasted time entering it!). Remember to update your spreadsheet with each paper you read and made a decision on.\nThe article I enter has 3 experiments, and the first is with adult participants. Do I need to enter this experiment?\nNo, please only enter the infant/child experiments\nWhat level of detail should I report? The sound stimuli differ approx. 6 ms in length, but the experiment is not about length differences. Do I have to report this difference although it is very small?\nIn case there’s a column for stimulus length, please report it. You are right that this experiment is not about length differences, but having the information cannot hurt, and eventual analyses will reflect that the difference is very small.\nThe article reports a table with the lengths of each individual stimulus. Should I calculate and report the average value?\nYes, please report the averaged value in the appropriate column.\nI am entering an article with the HAS method. The authors report results for both the 2 and 4 minutes after the test phase has started. Your example only reports the results after 2 minutes, but would you still want me to report both?\nIt is often the case that articles report more than one type of result. Please just report the ones that we also provide in the example file!\nRegression and moderator analysis ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"da76c0969c24e015fdd91d97b072f39b","permalink":"https://langcog.github.io/metalab/documentation/using_ma_data/conduct_ma/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/using_ma_data/conduct_ma/","section":"documentation","summary":"Build a MA Choosing the right MA question How do I define my MA question? Choose the appropriate level of detail for your MA topic. The topic of your meta-analysis should be broader than the one of a single experiment (e.g. “How do babies segment words of different stress patterns?”), but narrower than a whole research field (e.g. “How do babies learn language?”). The goal is to be able to gather comparable papers, measuring consistant dependant variables, to allow you to compute a common statistical metric (i.","tags":null,"title":"Conduct MA","type":"book"},{"authors":null,"categories":null,"content":"To ensure that new datasets being added to the MetaLab website are valid, run the Data Validation application. The application tests the new datasets on different criteria, such as the existence of necessary columns (ex. fields in the “long_cite” column are required), the appropriate length of a certain column (ex. fields in the “short_cite” column should be less than length of 60 characters), and the appropriate range of a certain column (ex. fields in the “corr” column should have a value between -1 and 1).\nThe data validation tool allows you to validate datasets from 3 different sources:\nMetaLab Data - these datasets are already part of the MetaLab database\nExternal URL - this allows you to validate a Google sheet by providing the Google sheet URL\nUpload CSV - this allows you to validate a csv file that is on your local computer\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d5b4aafde2c949e11f2144c544bce005","permalink":"https://langcog.github.io/metalab/documentation/shinyapps/data-validation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/shinyapps/data-validation/","section":"documentation","summary":"To ensure that new datasets being added to the MetaLab website are valid, run the Data Validation application. The application tests the new datasets on different criteria, such as the existence of necessary columns (ex. fields in the “long_cite” column are required), the appropriate length of a certain column (ex. fields in the “short_cite” column should be less than length of 60 characters), and the appropriate range of a certain column (ex.","tags":null,"title":"Data Validator","type":"book"},{"authors":null,"categories":null,"content":"install metalabr\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3a1a30b66c80b23cf4957ba67008d558","permalink":"https://langcog.github.io/metalab/documentation/rpackage/using/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/rpackage/using/","section":"documentation","summary":"install metalabr","tags":null,"title":"Installation","type":"book"},{"authors":null,"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"74c8c4dc7374fe7c7909f9ae05355982","permalink":"https://langcog.github.io/metalab/app/power-analysis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/app/power-analysis/","section":"app","summary":"Analyzes power of your experiment under a variety of conditions","tags":null,"title":"Power Analysis","type":"shinyapp"},{"authors":null,"categories":null,"content":"This page is under revision, access the previous tutorial here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7f02877296d6fa941c8fbf18357316d6","permalink":"https://langcog.github.io/metalab/documentation/shinyapps/power-analysis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/shinyapps/power-analysis/","section":"documentation","summary":"This page is under revision, access the previous tutorial here.","tags":null,"title":"Power Analysis","type":"book"},{"authors":null,"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1059d3766e52b5148b4852da414a2a3","permalink":"https://langcog.github.io/metalab/app/power-simulation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/app/power-simulation/","section":"app","summary":"Simulate power of meta-analyses under a variety of conditions","tags":null,"title":"Power Simulation","type":"shinyapp"},{"authors":null,"categories":null,"content":"This page is under revision, access the previous tutorial here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1ab91b8a6bbc20a6952a9fe11c5da391","permalink":"https://langcog.github.io/metalab/documentation/shinyapps/power-simulation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/shinyapps/power-simulation/","section":"documentation","summary":"This page is under revision, access the previous tutorial here.","tags":null,"title":"Power Simulation","type":"book"},{"authors":null,"categories":null,"content":"install metalabr\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2b8f81170ba5f67f3dc6e6fda324c9c","permalink":"https://langcog.github.io/metalab/documentation/rpackage/usage/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/rpackage/usage/","section":"documentation","summary":"install metalabr","tags":null,"title":"Usage","type":"book"},{"authors":null,"categories":null,"content":"This page is under revision, access the previous tutorial here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0ca32a91a769023c31c2c4617f7201f4","permalink":"https://langcog.github.io/metalab/documentation/shinyapps/viz/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/shinyapps/viz/","section":"documentation","summary":"This page is under revision, access the previous tutorial here.","tags":null,"title":"Visualization","type":"book"},{"authors":null,"categories":null,"content":" How to contribute a meta-analysis (MA) to MetaLab? We welcome researchers interested in contributing to MetaLab. Please contact us at metalab-project@googlegroups.com or any of our Team Members if you have questions.\nResources\nHere are a few resources on creating meta-analyses compatible with Metalab:\nMetalab MA template Code book Interrogating PubMed via a script Selecting studies for inclusion FAQ InWordDB, a well-fleshed out MA Instructions for creating a community-augmented meta-analysis (including further resources) Contribute your meta-analysis If you have already done a meta-analysis, you can easily add it to MetaLab. This tutorial explains how. But first, we go over why this is good for you and the community.\nWhy should I contribute my meta-analysis to MetaLab? Contributing to MetaLab can have several advantages both for you and the community:\n* Get more visibility for your MA. When publishing a paper, you wish that it will be read by as many people as possible. Placing it in a centralized repository such as MetaLab can help you to reach this broad audience and gives more visibility to your meta-analysis.\n* Increase the impact of your MA. As an author, you probably want your results to be fully understood by readers, and you want your readers to use your data as efficiently as possible. The interactive interface of the MetaLab website allows readers to better navigate in your meta-analysis results than the paper version, and to play with the results to better use them when planning experiments. MetaLab is an opportunity for your meta-analysis to make a stronger impact.\n* Contribute to drawing the broader developmental picture. You made a meta-analysis to help the community draw a clearer picture about an effect of interest and contribute to theory assessment. MetaLab is a central platform that includes over 1040 effect sizes. Incorporating your meta-analysis in this larger dataset helps the community to have a better idea of cognitive development and language acquisition.\nWho owns the data contributed to MetaLab? You remain the owner of your meta-analysis data: Users must cite your data by your preferred citation. If your data are previously unpublished then this doesn’t count as publication. Learn more by reading our full citation policy.\nCan I retain control on my data? Must I forever retain control of my data? You can retain control for as long as you want to. In fact, two options exists for the curation and review of your data. You can choose to be the curator. This means you agree to be the person responsible for identifying new relevant papers and signaling them to the MetaLab data manager, who will add them to the database of the relevant MA. You would be expected to check data entry once in a while. Curators are part of the MetaLab board and get informed of discussions regarding e.g. site revamping. Alternatively, you can choose to step down completely, and it will be MetaLab’s job to assign a new curator for your dataset. In this case, we can still keep your photo on the wall of fame.\nHow do I code my existing meta-analysis in the MetaLab format ? We prepared a spreadsheet that you must use to code your data. The key property of this spreadsheet is that it has one row for each effect size. Therefore you should fill as many rows as the number of effect size you report in your meta-analysis.\n* The first tab, called “Data”, should contain your data.\n* The second tab, called “CodeBook”, contains all the explanations about the codes to be used when you fill the “Data” tab.\n* The third tab, called “Methods”, contains all the possible options for the “method” column and their respective description.\nFollow these steps to convert your data:\nMake a copy of the spreadsheet.\nRename the copy with an informative name to identify your MA: FirstAuthor_Topic (e.g. Dunst_motionese_preference).\nCreate a new tab and copy-paste your data table there.\nMake a copy of the “Data” tab to keep an interim version of your data.\nCopy the first column of the tab containing your data table. Then go to the new “InterimData” tab and paste your first column in the MetaLab column that matches.\nRepeat step 5 for each column of your data table.\nCopy the first column of the “InterimData” in the “Data” tab. Then edit each cell to match the data format specified in the “CodeBook” tab. If you work from your paper, you may have an appendix or a table for each of your moderators. In this case, take them one by one and follow these steps:\nCreate a tab and copy-paste your appendix or table there. Check that the content of your appendix hasn’t been messed up when pasting. Rename the tab with the name of your moderator. Edit the data to have one row per effect size. If you have several tables/appendix, repeat step 1-2 for each of them. If you have several appendix create another tab and copy paste the content of all appendix-specific tabs side-by-side to check that all lines match up (i.e. same number of effect sizes in all the appendix/tables). Once you have synthesized all your appendix in one table, copy-paste the column corresponding to a MetaLab requirement in the “Data” tab and edit each cell to match the data format specified in the “CodeBook” tab. What if an effect size is computed with groups from two different papers ? Write the two references in each of the first three columns (study_ID, long_cite, short_cite), separated by commas. The “short cite columns” should be in the text citation format, i.e. Smith (2002, 2008), if the two papers are from the same authors. Fill the other columns as usual.\nWhat if I don’t have all the columns required by MetaLab ? Fill the missing columns with “NA”. If it happens that you don’t have one of the mandatory columns, please let us know.\nWhat types of communications are considered as peer-reviewed ? Most journal articles are peer-reviewed; some conference proceedings (e.g., Cognitive Science) are peer-reviewed. Typically, book chapters, posters, and conference abstract are not considered peer-reviewed because no reviewer has seen the full details of the methods.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a14fd02ce495206076665b2ffd3ed812","permalink":"https://langcog.github.io/metalab/documentation/using_ma_data/contribute_ma/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/using_ma_data/contribute_ma/","section":"documentation","summary":"How to contribute a meta-analysis (MA) to MetaLab? We welcome researchers interested in contributing to MetaLab. Please contact us at metalab-project@googlegroups.com or any of our Team Members if you have questions.\nResources\nHere are a few resources on creating meta-analyses compatible with Metalab:\nMetalab MA template Code book Interrogating PubMed via a script Selecting studies for inclusion FAQ InWordDB, a well-fleshed out MA Instructions for creating a community-augmented meta-analysis (including further resources) Contribute your meta-analysis If you have already done a meta-analysis, you can easily add it to MetaLab.","tags":null,"title":"Contribute MA","type":"book"},{"authors":null,"categories":null,"content":" This page is under revision, access the previous tutorial here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"abb10d086f02b5061ec73e17158e270b","permalink":"https://langcog.github.io/metalab/documentation/using_ma_data/update_existing_ma/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/using_ma_data/update_existing_ma/","section":"documentation","summary":"This page is under revision, access the previous tutorial here.","tags":null,"title":"Update Existing MA","type":"book"},{"authors":null,"categories":null,"content":" This page is under revision, access the previous tutorial here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3380a22c8aee10ca32574da3ba486a05","permalink":"https://langcog.github.io/metalab/documentation/using_ma_data/plan_studies_interpret_results/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/using_ma_data/plan_studies_interpret_results/","section":"documentation","summary":"This page is under revision, access the previous tutorial here.","tags":null,"title":"Planning Studies and Interpreting Results","type":"book"},{"authors":null,"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cf720402390c489dae050e1dd9eded64","permalink":"https://langcog.github.io/metalab/app/data-validation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/app/data-validation/","section":"app","summary":"Validate that new datasets are ready for inclusion in the MetaLab database","tags":null,"title":"Data Validation","type":"shinyapp"},{"authors":null,"categories":null,"content":"MetaLab allows researchers to use data available on its website. This can be by citing meta-analytic results, or downloading dataset and conducting custom analyses. In both cases our citation policy is the following:\nResearchers publishing or presenting work using data in MetaLab must cite the publications linked to that dataset, as listed in the Documentation. (If there is no citation, then no citation for the individual dataset is necessary).\nFor tracking use of MetaLab, please also cite at least one of the following:\nBergmann, C., Tsuji, S., Piccinini, P.E., Lewis, M.L., Braginsky, M., Frank, M.C., \u0026amp; Cristia, A. (2018). Promoting replicability in developmental research through meta-analyses: Insights from language acquisition research. Child Development, 89, 1996-2009 . DOI: 10.1111/cdev.13079 [Repository]\nLewis, M. L., Braginsky, M., Tsuji, S., Bergmann, C., Piccinini, P. E., Cristia, A., \u0026amp; Frank, M. C. (2017/under review). A Quantitative Synthesis of Early Language Acquisition Using Meta-Analysis. DOI: 10.17605/OSF.IO/HTSJM [Preprint]\nIf researchers use more than five datasets, we ask users as a courtesy to cite all data. But in case of severe space limitations, the database as a whole alone may be cited.\nSince the MetaLab site is dynamic, we recommend that you list the date of download for your data in your manuscript. For example: “We analyze all data currently in MetaLab (Bergmann et al., 2017). Data were downloaded on 06/17/17.”\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"42aefce0589a1b2e4c4e4e0da80a722d","permalink":"https://langcog.github.io/metalab/documentation/using_ma_data/citation_policy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/using_ma_data/citation_policy/","section":"documentation","summary":"MetaLab allows researchers to use data available on its website. This can be by citing meta-analytic results, or downloading dataset and conducting custom analyses. In both cases our citation policy is the following:\nResearchers publishing or presenting work using data in MetaLab must cite the publications linked to that dataset, as listed in the Documentation. (If there is no citation, then no citation for the individual dataset is necessary).\nFor tracking use of MetaLab, please also cite at least one of the following:","tags":null,"title":"Citation Policy","type":"book"},{"authors":null,"categories":null,"content":" Introduction Data available for each design choice variable Design choice variables by age Effect size by design choice variables By dataset Across datasets Introduction The research question determines many design choices in developmental research – e.g., is the hypothesis related to the timecourse of various pressures, or merely the presence of a bias? Some methods are better suited than others for answering these different questions. But, design choices can also influence the size of the effect: Some methods are less noisy than others, and therefore result in larger effects sizes. The size of the effect may further depend on the particular age of the child in a study, with some methods better suited to different age groups. Here we look across datasets in Metalab at four design choices – method, response mode, depenedent measure, and experimental design – and their relationship to effect sizes, and other variables of interest.\nThis report includes effect sizes for participants 60 months or younger.\nData available for each design choice variable Method\nmetalab_data \u0026lt;- metalab_data %\u0026gt;% filter(mean_age_months \u0026lt;= 60) metalab_data$method = as.factor(metalab_data$method) method.pd = metalab_data %\u0026gt;% group_by(method, dataset) %\u0026gt;% filter(n() \u0026gt; 3) %\u0026gt;% summarise(n = n()) ggplot(method.pd, aes(y = n, fill = dataset, x = method)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + xlab(\u0026quot;method\u0026quot;) + ylab(\u0026quot;N effect sizes\u0026quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + guides(fill=guide_legend(ncol=2)) Response Mode\nmetalab_data$response_mode = as.factor(metalab_data$response_mode) response.pd = metalab_data %\u0026gt;% group_by(response_mode, dataset) %\u0026gt;% summarise(n = n()) ggplot(response.pd, aes(y = n, fill = dataset, x = response_mode)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + xlab(\u0026quot;response mode\u0026quot;) + ylab(\u0026quot;N effect sizes\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + guides(fill=guide_legend(ncol=2)) Dependent Measure\nmetalab_data$dependent_measure= as.factor(metalab_data$dependent_measure) dm.pd = metalab_data %\u0026gt;% group_by(dependent_measure, dataset) %\u0026gt;% summarise(n = n()) ggplot(dm.pd, aes(y = n, fill = dataset, x = dependent_measure)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + xlab(\u0026quot;method\u0026quot;) + ylab(\u0026quot;N effect sizes\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + guides(fill=guide_legend(ncol=2)) Participant design\nmetalab_data$participant_design = as.factor(metalab_data$participant_design) participant_design.pd = metalab_data %\u0026gt;% group_by(participant_design, dataset) %\u0026gt;% summarise(n = n()) ggplot(participant_design.pd, aes(y = n, fill = dataset, x = participant_design)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + xlab(\u0026quot;participant design\u0026quot;) + ylab(\u0026quot;N effect sizes\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + guides(fill=guide_legend(ncol=2)) Design choice variables by age age.response_mode.pd = metalab_data %\u0026gt;% mutate(mean_age_months_rounded = cut_width(mean_age_months, width = 3, boundary = 0)) %\u0026gt;% group_by(mean_age_months_rounded, response_mode) %\u0026gt;% summarise(n = n()) %\u0026gt;% mutate(prop = n / sum(n)) ggplot(age.response_mode.pd, aes(x = mean_age_months_rounded, y = prop, color = response_mode)) + geom_point() + geom_line(aes(group = response_mode)) + xlab(\u0026quot;Age (months)\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Response Mode\u0026quot;) ggplot(age.response_mode.pd, aes(x = mean_age_months_rounded, y = n, color = response_mode)) + geom_point() + geom_line(aes(group = response_mode)) + xlab(\u0026quot;Age (months)\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Response Mode\u0026quot;) age.method.pd = metalab_data %\u0026gt;% mutate(mean_age_months_rounded = cut_width(mean_age_months, width = 3, boundary = 0)) %\u0026gt;% group_by(mean_age_months_rounded, method) %\u0026gt;% summarise(n = n()) %\u0026gt;% mutate(prop = n / sum(n)) ggplot(age.method.pd, aes(x = mean_age_months_rounded, y = prop, color = method)) + geom_point() + geom_line(aes(group = method)) + xlab(\u0026quot;Age (months)\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Method\u0026quot;) ggplot(age.method.pd, aes(x = mean_age_months_rounded, y = n, color = method)) + geom_point() + geom_line(aes(group = method)) + xlab(\u0026quot;Age (months)\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Method\u0026quot;) age.dm.pd = metalab_data %\u0026gt;% mutate(mean_age_months_rounded = cut_width(mean_age_months, width = 3, boundary = 0)) %\u0026gt;% group_by(mean_age_months_rounded, dependent_measure) %\u0026gt;% summarise(n = n()) %\u0026gt;% mutate(prop = n / sum(n)) ggplot(age.dm.pd, aes(x = mean_age_months_rounded, y = prop, color = dependent_measure)) + geom_point() + geom_line(aes(group = dependent_measure)) + xlab(\u0026quot;Age (months)\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Dependent Measure\u0026quot;) ggplot(age.dm.pd, aes(x = mean_age_months_rounded, y = n, color = dependent_measure)) + geom_point() + geom_line(aes(group = dependent_measure)) + xlab(\u0026quot;Age (months)\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Dependent Measure\u0026quot;) age.pd.pd = metalab_data %\u0026gt;% mutate(mean_age_months_rounded = cut_width(mean_age_months, width = 3, boundary = 0)) %\u0026gt;% group_by(mean_age_months_rounded, participant_design) %\u0026gt;% summarise(n = n()) %\u0026gt;% mutate(prop = n / sum(n)) ggplot(age.pd.pd, aes(x = mean_age_months_rounded, y = prop, color = participant_design)) + geom_point() + geom_line(aes(group = participant_design)) + xlab(\u0026quot;Age (months)\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Participant Design\u0026quot;) ggplot(age.pd.pd, aes(x = mean_age_months_rounded, y = n, color = participant_design)) + geom_point() + geom_line(aes(group = participant_design)) + xlab(\u0026quot;Age (months)\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Participant Design\u0026quot;) Effect size by design choice variables By dataset Get residual effect size, controling for age and phenonmenon\nfull.model = rma(d_calc ~ dataset + mean_age_1, vi = d_var_calc, data = metalab_data, method = \u0026quot;REML\u0026quot;) residuals = rstandard(full.model) metalab_data = metalab_data %\u0026gt;% bind_cols(as.data.frame(residuals$resid), as.data.frame(residuals$z)) %\u0026gt;% rename(residual.d = `residuals$resid`, residual.d.s = `residuals$z`) # standardized method.pd = metalab_data %\u0026gt;% group_by(method, dataset) %\u0026gt;% summarise(residual.d = mean(residual.d), n = n()) ggplot(method.pd, aes(x = method, y = residual.d, color = dataset)) + geom_point(aes(size = n)) + geom_line(aes(group = dataset)) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Method\u0026quot;) + guides(colour=guide_legend(ncol=2)) response.pd = metalab_data %\u0026gt;% group_by(response_mode, dataset) %\u0026gt;% summarise(residual.d = mean(residual.d), n = n()) ggplot(response.pd, aes(x = response_mode, y = residual.d, color = dataset)) + geom_point(aes(size = n)) + geom_line(aes(group = dataset)) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Response Mode\u0026quot;) + guides(colour=guide_legend(ncol=2)) dm.pd = metalab_data %\u0026gt;% group_by(dependent_measure, dataset) %\u0026gt;% summarise(residual.d = mean(residual.d), n = n()) ggplot(dm.pd, aes(x = dependent_measure, y = residual.d, color = dataset)) + geom_point(aes(size = n)) + geom_line(aes(group = dataset)) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Dependent Measure\u0026quot;) + guides(colour=guide_legend(ncol=2)) participant_design.pd = metalab_data %\u0026gt;% group_by(participant_design, dataset) %\u0026gt;% summarise(residual.d = mean(residual.d), n = n()) ggplot(participant_design.pd, aes(x = participant_design, y = residual.d, color = dataset)) + geom_point(aes(size = n)) + geom_line(aes(group = dataset)) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + ggtitle(\u0026quot;Participant Design\u0026quot;) + guides(colour=guide_legend(ncol=2)) Across datasets method.pd.all = metalab_data %\u0026gt;% group_by(method) %\u0026gt;% multi_boot_standard(col = \u0026quot;residual.d\u0026quot;) %\u0026gt;% ungroup() %\u0026gt;% mutate(method = reorder(method, mean)) ggplot(method.pd.all, aes(x = method, y = mean, fill = method)) + geom_bar(position=\u0026quot;dodge\u0026quot;, stat=\u0026quot;identity\u0026quot;) + geom_errorbar(aes(ymin = ci_lower, ymax= ci_upper), width=0.2, position=\u0026quot;dodge\u0026quot;) + ylab(\u0026quot;residual effect size\u0026quot;) + xlab(\u0026quot;method\u0026quot;) + theme(legend.position=\u0026quot;none\u0026quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) response.pd.all = metalab_data %\u0026gt;% group_by(response_mode) %\u0026gt;% multi_boot_standard(col = \u0026quot;residual.d\u0026quot;) %\u0026gt;% ungroup() %\u0026gt;% mutate(response_mode = reorder(response_mode, mean)) ggplot(response.pd.all, aes(x = response_mode, y = mean, fill = response_mode)) + geom_bar(position=\u0026quot;dodge\u0026quot;, stat=\u0026quot;identity\u0026quot;) + geom_errorbar(aes(ymin = ci_lower, ymax= ci_upper), width=0.2, position=\u0026quot;dodge\u0026quot;) + ylab(\u0026quot;residual effect size\u0026quot;) + xlab(\u0026quot;response mode\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) dm.pd.all = metalab_data %\u0026gt;% group_by(dependent_measure) %\u0026gt;% multi_boot_standard(col = \u0026quot;residual.d\u0026quot;) %\u0026gt;% ungroup() %\u0026gt;% mutate(dependent_measure = reorder(dependent_measure, mean)) ggplot(dm.pd.all, aes(x =dependent_measure, y = mean, fill = dependent_measure)) + geom_bar(position=\u0026quot;dodge\u0026quot;, stat=\u0026quot;identity\u0026quot;) + geom_errorbar(aes(ymin = ci_lower, ymax= ci_upper), width=0.2, position=\u0026quot;dodge\u0026quot;) + ylab(\u0026quot;residual effect size\u0026quot;) + xlab(\u0026quot;dependent measure\u0026quot;) + theme(legend.position=\u0026quot;none\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) participant_design.pd.all = metalab_data %\u0026gt;% group_by(participant_design) %\u0026gt;% multi_boot_standard(col = \u0026quot;residual.d\u0026quot;) %\u0026gt;% ungroup() %\u0026gt;% mutate(participant_design = reorder(participant_design, mean)) ggplot(participant_design.pd.all, aes(x = participant_design, y = mean, fill = participant_design)) + geom_bar(position=\u0026quot;dodge\u0026quot;, stat=\u0026quot;identity\u0026quot;) + geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width=0.2, position=\u0026quot;dodge\u0026quot;) + ylab(\u0026quot;residual effect size\u0026quot;) + xlab(\u0026quot;participant design\u0026quot;) + theme(legend.position=\u0026quot;none\u0026quot;) + theme (axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) ","date":1679961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679961600,"objectID":"f3e044751b11ee5bace806607ebde319","permalink":"https://langcog.github.io/metalab/report/method_choice/","publishdate":"2023-03-28T00:00:00Z","relpermalink":"/report/method_choice/","section":"report","summary":"The research question determines many design choices in developmental research -- e.g., is the hypothesis related to the timecourse of various pressures, or merely the presence of a bias? Some methods are better suited than others for answering these different questions.","tags":null,"title":"Design Choice Analyses","type":"report"},{"authors":null,"categories":null,"content":" Introduction Simple random effects structure Complex random effects structure (nested paper effects) Complex random effects structure (random slope) Subset to only those papers with multiple ages Two age groups Three age groups Conclusions Introduction The goal for this analysis was to better understand the shape of the developmental curve. To do this we used linear mixed effects models, so that the variance of individual meta-analyses could be accounted for.\nSummary of investigations:\nMeta-analytic mixed-effects are promising, but… The random effects structure (specifically if we nest paper effects within meta-analysis) makes a big difference to the implied curve shape. Subsetting to only studies with multiple age groups improves performance. Simple random effects structure Below is our data set separated by meta-analysis with four curve types: 1) linear, 2) logarithmic, 3) quadratic, and 4) both linear and logarithmic predictors.\nWe ran mixed effects regressions where meta-analysis (data set) was included as a random intercept for our four models. We then ran Chi-squared tests to compare the different models to one another. Model comparison found the quadratic model to be a better fit than the linear model and the logarithmic model, but no difference between the linear and logarithmic model. The two predictor model (linear and log) also outperformed both the single predictor linear model and the single predictor logarithmic model.\nlin_lmer \u0026lt;- lmer(d_calc ~ mean_age + (1 | dataset), weights = 1/d_var_calc, REML = F, data = metalab_data) log_lmer \u0026lt;- lmer(d_calc ~ log(mean_age) + (1 | dataset), weights = 1/d_var_calc, REML = F, data = metalab_data) quad_lmer \u0026lt;- lmer(d_calc ~ I(mean_age^2) + (1 | dataset), weights = 1/d_var_calc, REML = F, data = metalab_data) lin_log_lmer \u0026lt;- lmer(d_calc ~ mean_age + log(mean_age) + (1| dataset), weights = 1/d_var_calc, REML = F, data = metalab_data) kable(coef(summary(lin_lmer))) Estimate Std. Error t value (Intercept) 0.2670887 0.0475926 5.611980 mean_age 0.0001009 0.0000283 3.568062 kable(coef(summary(log_lmer))) Estimate Std. Error t value (Intercept) 0.3481420 0.0812957 4.2824150 log(mean_age) -0.0053545 0.0113850 -0.4703164 kable(coef(summary(quad_lmer))) Estimate Std. Error t value (Intercept) 0.3141646 0.047736 6.581288 I(mean_age^2) 0.0000000 0.000000 1.167392 kable(coef(summary(lin_log_lmer))) Estimate Std. Error t value (Intercept) 0.3970884 0.0810391 4.899959 mean_age 0.0001246 0.0000308 4.049988 log(mean_age) -0.0245490 0.0123287 -1.991208 kable(anova(lin_lmer, log_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) lin_lmer 4 4934.287 4958.137 -2463.143 4926.287 NA NA NA log_lmer 4 4946.628 4970.478 -2469.314 4938.628 0 0 NA kable(anova(lin_lmer, quad_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) lin_lmer 4 4934.287 4958.137 -2463.143 4926.287 NA NA NA quad_lmer 4 4945.485 4969.334 -2468.742 4937.485 0 0 NA kable(anova(log_lmer, quad_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) log_lmer 4 4946.628 4970.478 -2469.314 4938.628 NA NA NA quad_lmer 4 4945.485 4969.334 -2468.742 4937.485 1.143673 0 NA kable(anova(lin_lmer, lin_log_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) lin_lmer 4 4934.287 4958.137 -2463.143 4926.287 NA NA NA lin_log_lmer 5 4932.349 4962.161 -2461.175 4922.349 3.937882 1 0.0472102 kable(anova(log_lmer, lin_log_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) log_lmer 4 4946.628 4970.478 -2469.314 4938.628 NA NA NA lin_log_lmer 5 4932.349 4962.161 -2461.175 4922.349 16.27928 1 5.47e-05 Focusing on the linear, log, and two predictor (linear and log) models, we built predictions for all complete meta-analyses. The plot separated by meta-analysis is presented below. The linear and two predictor models are pretty similar, mainly being different at very early ages.\nmetalab_data_preds \u0026lt;- metalab_data %\u0026gt;% select(dataset, short_name, d_calc, d_var_calc, mean_age, study_ID) %\u0026gt;% filter(complete.cases(.)) %\u0026gt;% mutate(lin_pred = predict(lin_lmer)) %\u0026gt;% mutate(log_pred = predict(log_lmer)) %\u0026gt;% mutate(lin_log_pred = predict(lin_log_lmer)) Overall this method looks pretty good. It seems like the linear predictor in the two predictor model is smoothing the logs at the edges, and the random effects are working to capture cross data set variability.\nComplex random effects structure (nested paper effects) We decided to expand our random effects structure to include paper (study_ID) nested in meta-analysis (data set) to capture the fact that a given meta-analysis has a specific set of papers, and may have multiple entries from the same paper. Here we focused on the two predictor model. The simpler random effects model from above is repeated here for easy comparison. A Chi-squared test finds a significant difference between the models, with the model with the more complex random effects structure having a lower AIC.\nmetalab_data \u0026lt;- metalab_data %\u0026gt;% select(d_calc, d_var_calc, mean_age, dataset, study_ID) %\u0026gt;% filter(complete.cases(.)) lin_log_paper_lmer \u0026lt;- lmer(d_calc ~ mean_age + log(mean_age) + (1 | dataset / study_ID), weights = 1/d_var_calc, REML = F, data = metalab_data) kable(coef(summary(lin_log_paper_lmer))) Estimate Std. Error t value (Intercept) 0.2326822 0.1001005 2.3244861 mean_age 0.0000973 0.0000353 2.7569361 log(mean_age) 0.0137338 0.0162846 0.8433582 kable(coef(summary(lin_log_lmer))) Estimate Std. Error t value (Intercept) 0.3970884 0.0810391 4.899959 mean_age 0.0001246 0.0000308 4.049988 log(mean_age) -0.0245490 0.0123287 -1.991208 kable(anova(lin_log_lmer, lin_log_paper_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) lin_log_lmer 5 4932.349 4962.161 -2461.175 4922.349 NA NA NA lin_log_paper_lmer 6 4688.059 4723.834 -2338.030 4676.059 246.2897 1 0 We then predicted from this new, more complex model and compare it to the model without the nested paper random effects structure. Initial testing found that including the nested random effect in the predict algorithm led to massive overfitting, so just the simple random effects structure was used to compute predictions. Below is the figure comparing the two curves. The curves are very similar, suggesting that while adding the nesting of paper does significantly improve the model, visually the difference is very small.\nlin_log_paper_preds \u0026lt;- predict(lin_log_paper_lmer, re.form = ~ (1 | dataset)) metalab_data_preds \u0026lt;- metalab_data_preds %\u0026gt;% mutate(lin_log_paper_pred = lin_log_paper_preds) Complex random effects structure (random slope) Another way to make the random effects structure more complex is to add a random slope to the model. Two more models were built with a random slope by mean age log transformed, one without the nesting of paper, and one with the nesting of paper. Summaries of the new models with the random slope and the previous models without the random slope are below. Model comparison found that the model with nested structure and the slope was better than the simplest model (no nesting, no slope). The model with both the nested structure and the slope was also better than than the model with only the slope. Based on this it appears that the best model is one that includes both the nested random effects structure and a random slope of mean age log transformed.\nlin_log_slope_lmer \u0026lt;- lmer(d_calc ~ mean_age + log(mean_age) + (log(mean_age)| dataset), weights = 1/d_var_calc, REML = F, data = metalab_data) lin_log_paper_slope_lmer \u0026lt;- lmer(d_calc ~ mean_age + log(mean_age) + (log(mean_age)| dataset / study_ID), weights = 1/d_var_calc, REML = F, data = metalab_data) kable(coef(summary(lin_log_slope_lmer))) Estimate Std. Error t value (Intercept) -0.2312963 0.4081625 -0.5666771 mean_age 0.0000813 0.0000588 1.3828775 log(mean_age) 0.0833884 0.0720156 1.1579213 kable(coef(summary(lin_log_paper_slope_lmer))) Estimate Std. Error t value (Intercept) -0.4349814 0.4545730 -0.9569011 mean_age 0.0001308 0.0000807 1.6212193 log(mean_age) 0.1202801 0.0814058 1.4775381 kable(coef(summary(lin_log_lmer))) Estimate Std. Error t value (Intercept) 0.3970884 0.0810391 4.899959 mean_age 0.0001246 0.0000308 4.049988 log(mean_age) -0.0245490 0.0123287 -1.991208 kable(coef(summary(lin_log_paper_lmer))) Estimate Std. Error t value (Intercept) 0.2326822 0.1001005 2.3244861 mean_age 0.0000973 0.0000353 2.7569361 log(mean_age) 0.0137338 0.0162846 0.8433582 kable(anova(lin_log_lmer, lin_log_slope_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) lin_log_lmer 5 4932.349 4962.161 -2461.175 4922.349 NA NA NA lin_log_slope_lmer 7 4861.500 4903.237 -2423.750 4847.500 74.84898 2 0 kable(anova(lin_log_lmer, lin_log_paper_slope_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) lin_log_lmer 5 4932.349 4962.161 -2461.175 4922.349 NA NA NA lin_log_paper_slope_lmer 10 4588.510 4648.134 -2284.255 4568.510 353.8394 5 0 kable(anova(lin_log_paper_lmer, lin_log_slope_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) lin_log_paper_lmer 6 4688.059 4723.834 -2338.03 4676.059 NA NA NA lin_log_slope_lmer 7 4861.500 4903.237 -2423.75 4847.500 0 1 1 kable(anova(lin_log_paper_lmer, lin_log_paper_slope_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) lin_log_paper_lmer 6 4688.059 4723.834 -2338.030 4676.059 NA NA NA lin_log_paper_slope_lmer 10 4588.510 4648.134 -2284.255 4568.510 107.5498 4 0 kable(anova(lin_log_slope_lmer, lin_log_paper_slope_lmer)) npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) lin_log_slope_lmer 7 4861.50 4903.237 -2423.750 4847.50 NA NA NA lin_log_paper_slope_lmer 10 4588.51 4648.134 -2284.255 4568.51 278.9904 3 0 As before, predictions were built for the new models and plotted on the data. Overall the models do look pretty similar in terms of their predicted fit of the data.\nlin_log_slope_preds \u0026lt;- predict(lin_log_slope_lmer, re.form = ~ (log(mean_age) | dataset)) lin_log_paper_slope_preds \u0026lt;- predict(lin_log_paper_slope_lmer, re.form = ~ (log(mean_age) | dataset)) metalab_data_preds \u0026lt;- metalab_data_preds %\u0026gt;% mutate(lin_log_slope_pred = lin_log_slope_preds) %\u0026gt;% mutate(lin_log_paper_slope_pred = lin_log_paper_slope_preds) Subset to only those papers with multiple ages One concern with using a random slope with meta-analysis nested by paper is that not all studies included more than one age group. To be sure that our random slope is really appropriate, here we look at only papers where more than one age group was tested.\nTwo age groups To start we arbitrarily decided on two age groups, at least more than two months apart. Below we build a new model only looking at data where papers had at least two age groups. The structure of the model is the same as the model with papers nested in meta-analysis and a random slope of mean age log transformed.\nmultiage_data \u0026lt;- metalab_data_preds %\u0026gt;% group_by(dataset, study_ID) %\u0026gt;% mutate(count_ages = length(unique(floor(mean_age/2)))) %\u0026gt;% filter(count_ages \u0026gt; 1) lin_log_paper_slope_multiage_lmer \u0026lt;- lmer(d_calc ~ mean_age + log(mean_age) + (log(mean_age) | dataset / study_ID), weights = 1/d_var_calc, REML = F, data = multiage_data) kable(coef(summary(lin_log_paper_slope_multiage_lmer))) Estimate Std. Error t value (Intercept) -0.4502116 0.4943054 -0.9107965 mean_age 0.0001879 0.0001040 1.8058519 log(mean_age) 0.1117848 0.0905963 1.2338777 Predictions were calculated for the new model and visually compared to the simple model on the full data set with no nested random effects and no random slope. The plot below suggests that for this reduced data set, the addition of the nested random effects and random slope does differ greatly from the simpler model.\nlin_log_paper_slope_multiage_preds \u0026lt;- predict(lin_log_paper_slope_multiage_lmer, re.form = ~ (log(mean_age)| dataset)) multiage_data \u0026lt;- multiage_data %\u0026gt;% ungroup %\u0026gt;% select(dataset, short_name, study_ID, d_calc, mean_age, d_var_calc, lin_log_pred) %\u0026gt;% mutate(lin_log_paper_slope_multiage_pred = lin_log_paper_slope_multiage_preds) Three age groups We also did the same analysis, but further reducing the data set to only papers that included at least three different age groups.\nmultiage_3_data \u0026lt;- metalab_data_preds %\u0026gt;% group_by(dataset, study_ID) %\u0026gt;% mutate(count_ages = length(unique(floor(mean_age/2)))) %\u0026gt;% filter(count_ages \u0026gt; 2) lin_log_paper_slope_multiage_3_lmer \u0026lt;- lmer(d_calc ~ mean_age + log(mean_age) + (log(mean_age) | dataset / study_ID), weights = 1/d_var_calc, REML = F, data = multiage_3_data) kable(coef(summary(lin_log_paper_slope_multiage_3_lmer))) Estimate Std. Error t value (Intercept) -0.4472534 0.5562647 -0.8040298 mean_age 0.0002398 0.0001211 1.9800306 log(mean_age) 0.1054403 0.1009791 1.0441802 Predictions were calculated for the new model and visually compared to the simple model on the full data set with no nested random effects and no random slope. The plot below suggests that for this further reduced data set, the difference becomes the two models becomes even more apparent.\nlin_log_paper_slope_multiage_3_preds \u0026lt;- predict(lin_log_paper_slope_multiage_3_lmer, re.form = ~ (log(mean_age)| dataset)) multiage_3_data \u0026lt;- multiage_3_data %\u0026gt;% ungroup %\u0026gt;% select(dataset, short_name, study_ID, d_calc, mean_age, d_var_calc, lin_log_pred) %\u0026gt;% mutate(lin_log_paper_slope_multiage_3_pred = lin_log_paper_slope_multiage_3_preds) Conclusions In this report we sought to find the best curve to describe developmental data. We found that, regarding predictors, the best fit of the data appears to be a model that includes both mean age and mean age log transformed as predictors. We further improved the curve by using complex random effects structures in our regressions. We found that a more complicated random effects structure was best by: 1) nesting paper in meta-analysis, and 2) including a random slope by mean age log transformed. This structure was most appropriate when we only looked at papers that had at least two or three age groups, to ensure the random slope applied to all data analyzed.\n","date":1679961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679961600,"objectID":"e3cc9ab2aac091610801fb09eb3939b3","permalink":"https://langcog.github.io/metalab/report/developmental_curves/","publishdate":"2023-03-28T00:00:00Z","relpermalink":"/report/developmental_curves/","section":"report","summary":"The goal for this analysis was to better understand the shape of the developmental curve. To do this we used linear mixed effects models, so that the variance of individual meta-analyses could be accounted for.","tags":null,"title":"Developmental curve comparison","type":"report"},{"authors":null,"categories":null,"content":" Introduction Base Model Two Level Model: Paper Three Level Model: Paper and Experiment Moderator Model from the Paper Two Level Model: Paper Three Level Model: Paper and Experiment Introduction Each effect size is nested within an experiment which is in turn nested within a paper (this includes unpublished reports, theses, and the likes). It can be assumed that effect sizes within these nested structures are not independent. Here we explore whether and how accounting for this possible correlation affects both a random effects base model and a moderator analysis. As example we chose InWordDB.\nBase Model Standard random effects model, no moderators. First we run the model without accounting for any hierarchical structure (as reported in the publication by Bergmann \u0026amp; Cristia 2015; note that differences in effect size estimation are due to an updated dataset here that also includes nonnative studies, as compared to the paper).\nlibrary(here) load(here(\u0026quot;shinyapps\u0026quot;, \u0026quot;site_data\u0026quot;, \u0026quot;Rdata\u0026quot;, \u0026quot;metalab.Rdata\u0026quot;)) inworddb \u0026lt;- droplevels(metalab_data[metalab_data$short_name==\u0026quot;inworddb\u0026quot;, ]) StandardMod \u0026lt;- rma(g_calc, g_var_calc, data = inworddb) summary(StandardMod) ## ## Random-Effects Model (k = 299; tau^2 estimator: REML) ## ## logLik deviance AIC BIC AICc ## -144.6900 289.3799 293.3799 300.7741 293.4206 ## ## tau^2 (estimated amount of total heterogeneity): 0.1023 (SE = 0.0115) ## tau (square root of estimated tau^2 value): 0.3199 ## I^2 (total heterogeneity / total variability): 76.99% ## H^2 (total variability / sampling variability): 4.35 ## ## Test for Heterogeneity: ## Q(df = 298) = 1143.3988, p-val \u0026lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## 0.2099 0.0218 9.6275 \u0026lt;.0001 0.1672 0.2526 *** ## ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 Two Level Model: Paper We first add a level for the paper a given effect size was reported in. These effect sizes presumably stem from a batch of studies that were conducted in the same lab in a very similar fashion and by the same set of experimenters, introducing possible correlations.\nPerPaperMod \u0026lt;- rma.mv(g_calc, g_var_calc, random = ~ 1 | short_cite, data = inworddb) summary(PerPaperMod) ## ## Multivariate Meta-Analysis Model (k = 299; method: REML) ## ## logLik Deviance AIC BIC AICc ## -268.1654 536.3308 540.3308 547.7250 540.3715 ## ## Variance Components: ## ## estim sqrt nlvls fixed factor ## sigma^2 0.0367 0.1916 68 no short_cite ## ## Test for Heterogeneity: ## Q(df = 298) = 1143.3988, p-val \u0026lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## 0.1832 0.0264 6.9494 \u0026lt;.0001 0.1315 0.2349 *** ## ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 Three Level Model: Paper and Experiment Nested within paper, we introduce a level for experiment number. Experiments can report several effect sizes, for example when infants are run in conditions; slight variations of the same study which are presumed to be even more similar than effect sizes within a paper. A caveat is that conventions on what counts as experiment and what counts as conditions within an experiment might differ across papers.\nPerExpPaperMod \u0026lt;- rma.mv(g_calc, g_var_calc, random = ~ factor(expt_num) | short_cite, data = inworddb) summary(PerExpPaperMod) ## ## Multivariate Meta-Analysis Model (k = 299; method: REML) ## ## logLik Deviance AIC BIC AICc ## -211.2785 422.5570 428.5570 439.6483 428.6386 ## ## Variance Components: ## ## outer factor: short_cite (nlvls = 68) ## inner factor: factor(expt_num) (nlvls = 15) ## ## estim sqrt fixed ## tau^2 0.0635 0.2521 no ## rho 0.2483 no ## ## Test for Heterogeneity: ## Q(df = 298) = 1143.3988, p-val \u0026lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## 0.1837 0.0265 6.9291 \u0026lt;.0001 0.1318 0.2357 *** ## ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 To summarize, all these models differ in their effect size estimates, but do not change the statistical outcome. The effect remains small but significantly above 0. Adding the level of experiment number did not dramatically change the result.\nModerator Model from the Paper #Centering mean age inworddb$ageC \u0026lt;- inworddb$mean_age-mean(inworddb$mean_age) StandardMod \u0026lt;- rma(g_calc, g_var_calc, mod = ageC, data = inworddb) summary(StandardMod) ## ## Mixed-Effects Model (k = 299; tau^2 estimator: REML) ## ## logLik deviance AIC BIC AICc ## -144.5660 289.1320 295.1320 306.2132 295.2139 ## ## tau^2 (estimated amount of residual heterogeneity): 0.1027 (SE = 0.0116) ## tau (square root of estimated tau^2 value): 0.3205 ## I^2 (residual heterogeneity / unaccounted variability): 77.04% ## H^2 (unaccounted variability / sampling variability): 4.36 ## R^2 (amount of heterogeneity accounted for): 0.00% ## ## Test for Residual Heterogeneity: ## QE(df = 297) = 1141.6702, p-val \u0026lt; .0001 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 0.3885, p-val = 0.5331 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## intrcpt 0.2099 0.0218 9.6125 \u0026lt;.0001 0.1671 0.2527 *** ## mods 0.0002 0.0003 0.6233 0.5331 -0.0004 0.0007 ## ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 Two Level Model: Paper PerPaperMod \u0026lt;- rma.mv(g_calc, g_var_calc, mod = ageC, random = ~ 1 | short_cite, data = inworddb) summary(PerPaperMod) ## ## Multivariate Meta-Analysis Model (k = 299; method: REML) ## ## logLik Deviance AIC BIC AICc ## -263.7595 527.5190 533.5190 544.6002 533.6009 ## ## Variance Components: ## ## estim sqrt nlvls fixed factor ## sigma^2 0.0414 0.2035 68 no short_cite ## ## Test for Residual Heterogeneity: ## QE(df = 297) = 1141.6702, p-val \u0026lt; .0001 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 9.6131, p-val = 0.0019 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## intrcpt 0.1806 0.0277 6.5200 \u0026lt;.0001 0.1263 0.2349 *** ## mods 0.0007 0.0002 3.1005 0.0019 0.0002 0.0011 ** ## ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 Three Level Model: Paper and Experiment PerExpPaperMod \u0026lt;- rma.mv(g_calc, g_var_calc, mod = ageC, random = ~ factor(expt_num) | short_cite, data = inworddb) summary(PerExpPaperMod) ## ## Multivariate Meta-Analysis Model (k = 299; method: REML) ## ## logLik Deviance AIC BIC AICc ## -209.1634 418.3268 426.3268 441.1017 426.4638 ## ## Variance Components: ## ## outer factor: short_cite (nlvls = 68) ## inner factor: factor(expt_num) (nlvls = 15) ## ## estim sqrt fixed ## tau^2 0.0663 0.2575 no ## rho 0.2952 no ## ## Test for Residual Heterogeneity: ## QE(df = 297) = 1141.6702, p-val \u0026lt; .0001 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 4.6265, p-val = 0.0315 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## intrcpt 0.1819 0.0276 6.5924 \u0026lt;.0001 0.1279 0.2360 *** ## mods 0.0005 0.0003 2.1509 0.0315 0.0000 0.0010 * ## ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 To summarize, introducing hierarchical structure changed the outcome for the moderator test. Age (centered) now has a small, but significant, effect on effect sizes. This is not the case when ignoring the nested structure of effect sizes. This result mirrors the reported analyses in Bergmann \u0026amp; Cristia (2015) that there is a small, positive effect of age when only considering papers which test at least two age groups in the same set-up.\n","date":1679961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679961600,"objectID":"cebe0cfabed2e95a00a3d4d3107d3f83","permalink":"https://langcog.github.io/metalab/report/hierarchicalrandomeffect/","publishdate":"2023-03-28T00:00:00Z","relpermalink":"/report/hierarchicalrandomeffect/","section":"report","summary":"Here we explore whether and how accounting for this possible correlation affects both a random effects base model and a moderator analysis.","tags":null,"title":"Hierarchical Random Effects in Meta-Analyses: Do they change stuff?","type":"report"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"08b3e9346c90602e76945c5a2fb536a6","permalink":"https://langcog.github.io/metalab/explore/apps/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/explore/apps/","section":"explore","summary":"Hello!","tags":null,"title":"Applications","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"f15ae9136a2ad28155ac7ca4d7674052","permalink":"https://langcog.github.io/metalab/explore/datasets/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/explore/datasets/","section":"explore","summary":"Hello!","tags":null,"title":"Applications","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"b068e6da8ff9b9af60b1c85b0fc63826","permalink":"https://langcog.github.io/metalab/explore/domains/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/explore/domains/","section":"explore","summary":"Hello!","tags":null,"title":"Applications","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"9b163c65e16fd7719b355d01dccc3083","permalink":"https://langcog.github.io/metalab/explore/reports/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/explore/reports/","section":"explore","summary":"Hello!","tags":null,"title":"Applications","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"3bf44c81f2a197de01edde90bcd77783","permalink":"https://langcog.github.io/metalab/team/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/team/","section":"","summary":"Hello!","tags":null,"title":"MetaLab Team","type":"widget_page"},{"authors":null,"categories":null,"content":" Abstract rule learning Rabagliati et al. (2018) N papers = 20, N experiments = 95, N participants = 1111 Can infants learn abstract repition rules from different types of stimuli? Curator is Hugh Rabagliati Search Strategy: Seeded with Marcus et al. (2010) in Google Scholar + manual search Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"92d4f3bfb57fc5c8b5a7741026a9c412","permalink":"https://langcog.github.io/metalab/dataset/rulelearning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/rulelearning/","section":"dataset","summary":"Can infants learn abstract repition rules from different types of stimuli?\n20 papers | 95 experiments | 1111 subjects","tags":["early_language"],"title":"Abstract rule learning","type":"dataset"},{"authors":null,"categories":null,"content":" Categorization bias N papers = 9, N experiments = 80, N participants = 328 In a triad-task, bias to generalize to taxonomic as opposed to thematic alternative. Curator is Molly Lewis Search Strategy: Seeded with Smiley and Brown (1979) in Google Scholar + manual search Systematic: no ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6b07bd0687f2917601a5b4daeb678e7e","permalink":"https://langcog.github.io/metalab/dataset/catbias/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/catbias/","section":"dataset","summary":"In a triad-task, bias to generalize to taxonomic as opposed to thematic alternative.\n9 papers | 80 experiments | 328 subjects","tags":["cognitive_development"],"title":"Categorization bias","type":"dataset"},{"authors":null,"categories":null,"content":" Cross-situational word learning Dal Ben et al. (2019) N papers = 16, N experiments = 50, N participants = 2271 Infants and children s abilities to learn words across multiple ambiguous situations. Curator is Rodrigo Dal Ben Search Strategy: database search, and seeded with Yu \u0026amp; Smith (2007) Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4590f667bc34b148b4693d0463019e9e","permalink":"https://langcog.github.io/metalab/dataset/crosssituational/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/crosssituational/","section":"dataset","summary":"Infants and children s abilities to learn words across multiple ambiguous situations.\n16 papers | 50 experiments | 2271 subjects","tags":["early_language"],"title":"Cross-situational word learning","type":"dataset"},{"authors":null,"categories":null,"content":" Familiar word recognition Carbajal et al. (2020) N papers = 16, N experiments = 34, N participants = 658 Do infants distingusih familiar words from novel/rare words in listening tasks? Curator is Julia Carbajal Search Strategy: Conceptual replications of Hallé \u0026amp; de Boysson-Bardies (1994) Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"55965bb30b242be3470829ea9921ae65","permalink":"https://langcog.github.io/metalab/dataset/famword/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/famword/","section":"dataset","summary":"Do infants distingusih familiar words from novel/rare words in listening tasks?\n16 papers | 34 experiments | 658 subjects","tags":["early_language"],"title":"Familiar word recognition","type":"dataset"},{"authors":null,"categories":null,"content":" Function word segmentation Bergmann \u0026amp; Cristia (2016) N papers = 5, N experiments = 17, N participants = 290 Recognition of familiarized function words from natural speech using behavioral methods. Curator is Christina Bergmann Search Strategy: \"We first generated a list of potentially relevant items to be included in our meta-analysis using the Google Scholar search engine, with the broad search term ‘infant word segmentation’ (following Gehanno, Rollin \u0026amp; Darmoni, 2013). This search was carried out on 27 November 2012 and we inspected the first 1000 results. Fifteen additional items were included based on recommendations and by scanning references of included papers. After removing duplicates, we screened the title and abstract of each remaining item and identified 231 items for full-text inspection using the following inclusion criteria: (1) original data were reported; (2) the stimulus material was continuous natural speech spoken in the participants’ native language; (3) the dependent measure was looking time (LT) at a neutral visual target (i.e. not a possible referent of one set of stimuli); (4) infants were normally developing.\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2a01e7141b7c86b19f07d66f92d630e8","permalink":"https://langcog.github.io/metalab/dataset/inworddb_function/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/inworddb_function/","section":"dataset","summary":"Recognition of familiarized function words from natural speech using behavioral methods.\n5 papers | 17 experiments | 290 subjects","tags":["early_language"],"title":"Function word segmentation","type":"dataset"},{"authors":null,"categories":null,"content":" Gaze following (live) Frank, Lewis, \u0026amp; MacDonald (2016) N papers = 12, N experiments = 33, N participants = 491 Gaze following using standard multi-alternative forced-choice paradigms. Curator is Molly Lewis Search Strategy: \"We identified papers using a Google Scholar search for “gaze following” and included those studies that (a) included data from typically-developing children, (b) used a standard face-to-face gaze-following task, and (c) reported percentage accuracy (rather than a score or other composite measure). Although we coded all papers that fit these criteria, we focused on papers with a simple two-alternative forced choice (9 papers); integrating across different numbers of alternatives added additional complexity to our model. In our first iteration of this analysis, we found that very few studies reported reaction times for gaze following, and those that did had no data from children older than 15 months and no data from gaze plus pointing. To remedy this issue we include new analyses of data from Yurovsky, Wade, \u0026amp; Frank (2013) and Yurovsky \u0026amp; Frank (2015).\" Systematic: no ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"91675d274b0422cdb01195fd8fbb583d","permalink":"https://langcog.github.io/metalab/dataset/gaze_following/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/gaze_following/","section":"dataset","summary":"Gaze following using standard multi-alternative forced-choice paradigms.\n12 papers | 33 experiments | 491 subjects","tags":["cognitive_development"],"title":"Gaze following (live)","type":"dataset"},{"authors":null,"categories":null,"content":" Gaze following (video) N papers = 15, N experiments = 52, N participants = 847 Gaze following using video-based first look paradigms Curator is Priya Silverstein Search Strategy: A search was conducted for studies using the Senju \u0026amp; Csibra (2008) paradigm of infant gaze-following. In order to find these, a search for the terms “gaze”, “follow” and “infant” was carried out on all peer-reviewed, published studies citing the original paper, resulting in 366 results. Abstracts were scanned to determine whether the full paper should be read, and full papers were included if they used the original paradigm with human typically developing infants and reported (or provided the data to calculate) the measure of first look difference score (congruent - incongruent). In total, 15 papers have been included. 4 additional papers were not included as information for calculating effect sizes could not be obtained from the manuscript. Systematic: no ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"08071fe1b4a8649915612f7eb12debb2","permalink":"https://langcog.github.io/metalab/dataset/vidgazefollow/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/vidgazefollow/","section":"dataset","summary":"Gaze following using video-based first look paradigms\n15 papers | 52 experiments | 847 subjects","tags":["cognitive_development"],"title":"Gaze following (video)","type":"dataset"},{"authors":null,"categories":null,"content":" Infant directed speech preference Dunst, Gorman, \u0026amp; Hamby (2012) N papers = 32, N experiments = 117, N participants = 1694 Looking times as a function of whether infant-directed vs. adult-directed speech is presented as stimulation. Curator is Alex Cristia Search Strategy: \"Studies were located using motherese or parentese or fatherese or infant directed speech or infant-directed speech or infant directed talk or child directed speech or child-directed speech or child directed talk or child-directed talk or baby talk AND infant* or neonate* or toddler* as search terms. Both controlled-vocabulary and natural-language searches were conducted (Lucas \u0026amp; Cutspec, 2007). Psychological Abstracts (PsychInfo), Educational Resource Information Center (ERIC), MEDLINE, Academic Search Premier, CINAHL, Education Resource Complete, and Dissertation Abstracts International were searched. These were supplemented by Google Scholar, Scirus, and Ingenta searches as well as a search of an extensive EndNote Library maintained by our Institute. Hand searches of the reference sections of all retrieved journal articles, book chapters, books, dissertations, and unpublished papers were also examined to locate additional studies. Studies were included if the effects of infant-directed speech on child behavior were compared to the effects of adult-directed speech on child behavior. Studies that intentionally manipulated word boundaries (e.g., Hirsh-Pasek et al., 1987; Nelson, Hirsh-Pasek, Jusczyk, \u0026amp; Cassidy, 1989) or used nonsense words or phrases (e.g., Mattys, Jusczyk, Luce, \u0026amp; Morgan, 1999; Thiessen, Hill, \u0026amp; Saffran, 2005) were excluded.\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b5d1ee7bf178a4e5d0287e8d09e2da8c","permalink":"https://langcog.github.io/metalab/dataset/idspref/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/idspref/","section":"dataset","summary":"Looking times as a function of whether infant-directed vs. adult-directed speech is presented as stimulation.\n32 papers | 117 experiments | 1694 subjects","tags":["early_language"],"title":"Infant directed speech preference","type":"dataset"},{"authors":null,"categories":null,"content":" Label advantage in concept learning Lewis \u0026amp; Long (unpublished) N papers = 18, N experiments = 102, N participants = 1664 Infants' categorization judgments in the presence and absence of labels. Curator is Molly Lewis Search Strategy: \"We conducted a forward search based on Balaban and Waxman (1997) in Google Scholar and Web of Science (October 2015). This was supplemented with papers identified through citations and publication lists on lab websites. The final sample included only peer-reviewed publications.\" Systematic: no ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"849f493a7fbed7ac0b8c95e1ad7f7012","permalink":"https://langcog.github.io/metalab/dataset/labadv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/labadv/","section":"dataset","summary":"Infants' categorization judgments in the presence and absence of labels.\n18 papers | 102 experiments | 1664 subjects","tags":["early_language"],"title":"Label advantage in concept learning","type":"dataset"},{"authors":null,"categories":null,"content":" Language discrimination and preference Gasparini, Langus, Tsuji, \u0026amp; Boll-Avetisyan (2020) N papers = 36, N experiments = 153, N participants = 2263 Discrimination of, or preference between, two language varieties, with results from various methods Curator is Loretta Gasparini Search Strategy: Published studies (n = 25) and an unpublished dataset (n = 1) already known to the investigators were included. A Google Scholar search was conducted on 17th April 2020 using Harzing’s Publish or Perish Windows GUI Edition 7.19 software with the following keyword combination: {\"infant\" OR \"infancy\" OR \"baby\"} \u0026amp; {\"language discrimination\" OR \"dialect discrimination\" OR \"accent discrimination\" OR \"rhythm class discrimination\"}. This search yielded over 3000 records, the first 500 of which were considered, and three unique studies were retained after abstract and full text screening. To identify infant studies that focussed on durational metrics, another Google Scholar search was conducted on 17th April 2020 with the keyword combination: {\"infant\" OR \"infancy\" OR \"baby\"} \u0026amp; {\"deltaC\"} \u0026amp; {\"rhythm\"}. This search yielded 299 results, all of which were considered, but no unique eligible studies were identified. Calls for studies were posted on the following mailing lists on April 16th, 2020: ICIS listserv, cogdevsoc listserv and the CHILDES mailing list, and three eligible studies were identified. The reference lists of all included studies and one review on the topic (Nazzi \u0026amp; Ramus, 2003) were checked, revealing eight unique eligible studies. We requested recommendations for studies from corresponding authors of included studies who could be contacted, and two eligible studies were thus identified. Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c4b141a2132a86493935946f2de7aad8","permalink":"https://langcog.github.io/metalab/dataset/langdiscrim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/langdiscrim/","section":"dataset","summary":"Discrimination of, or preference between, two language varieties, with results from various methods\n36 papers | 153 experiments | 2263 subjects","tags":["early_language"],"title":"Language discrimination and preference","type":"dataset"},{"authors":null,"categories":null,"content":" Mispronunciation sensitivity Von Holzen \u0026amp; Bergmann (2021) N papers = 32, N experiments = 251, N participants = 2047 Can infants distinguish correctly and mispronounced words, like dog and tog? Curator is Katie Von Holzen Search Strategy: Seeded with Swingley \u0026amp; Aslin (2000) in Google Scholar Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"dddb8e641e3a98ecad2bba7c67cf6177","permalink":"https://langcog.github.io/metalab/dataset/mps/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/mps/","section":"dataset","summary":"Can infants distinguish correctly and mispronounced words, like dog and tog?\n32 papers | 251 experiments | 2047 subjects","tags":["early_language"],"title":"Mispronunciation sensitivity","type":"dataset"},{"authors":null,"categories":null,"content":" Mutual exclusivity (Lewis, Cristiano, Lake, Kwan, \u0026amp; Frank, 2020) N papers = 48, N experiments = 146, N participants = 2505 Bias to assume that a novel word refers to a novel object in forced-choice paradigms. Curator is Molly Lewis Search Strategy: \"We conducted a forward search based on citations of Markman and Wachtel (1988) in Google Scholar (September 2013). We also searched from papers using the keyword combination ``mutual exclusivity'' in both PsychInfo and Google Scholar. We identified additional papers that were cited from this initial list. From these, we identified a relevant subset using the following criteria: (a) monolingual child participants, (b) one familiar object present at test, (c) referents were objects (not facts or object parts), (d) no incongruent cues (e.g. eye gaze at familiar object), and (e) peer-reviewed. We also included a series of studies reported in Frank et al. (2016).\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7147d9ae12ddeda216eeade25f29a3aa","permalink":"https://langcog.github.io/metalab/dataset/mutex/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/mutex/","section":"dataset","summary":"Bias to assume that a novel word refers to a novel object in forced-choice paradigms.\n48 papers | 146 experiments | 2505 subjects","tags":["early_language"],"title":"Mutual exclusivity","type":"dataset"},{"authors":null,"categories":null,"content":" Natural speech preference Issard, Tsuji, \u0026amp; Cristia (in prep.) N papers = 19, N experiments = 55, N participants = 770 Do infants prefer natural speech over other types of sound? Curator is Cecile Issard Search Strategy: database search Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"dc7fb8382782397644f4a27940c31bf7","permalink":"https://langcog.github.io/metalab/dataset/speechpref/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/speechpref/","section":"dataset","summary":"Do infants prefer natural speech over other types of sound?\n19 papers | 55 experiments | 770 subjects","tags":["early_language"],"title":"Natural speech preference","type":"dataset"},{"authors":null,"categories":null,"content":" Neonatal Imitation Davis et al., (2021) N papers = 26, N experiments = 336, N participants = 949 Does neonatal imitation exist? Insights from a meta-analysis of 336 effect sizes Curator is Jacqueline Davis Search Strategy: The search keywords included terms relevant to the predictor, the outcome, and the population. Both general outcome terms (e.g., “imitation”) and specific gestures (e.g., “tongue protrusion”) were used. Thus, each search query contained elements of both (a) “imitation” or “tongue protrusion” or “mouth opening” or “lip smacking” and (b) “neonates” or “infants” or “children.” We also searched the reference sections of previous reviews on neonatal imitation and the reference sections of included studies, and we requested unpublished datasets via a developmental psychology email list. All searches were limited to abstracts when this option was available. We selected electronic databases that included relevant journals in the fields of child development, infant psychology, and related fields and on the basis of source overlap and usability. In addition, we searched sources of unpublished literature, such as dissertations and theses, that may include null or negative results. The data sources selected were ProQuest (including ProQuest Dissertations and Theses), Scopus, PsycInfo (including PsycArticles), and Cambridge University Library and Dependent Libraries Catalogue. In addition, we searched Google Scholar using a more stringent set of search keywords. Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"13257530392a522c9dca5e8949fae2e2","permalink":"https://langcog.github.io/metalab/dataset/neonatal_imitation/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/neonatal_imitation/","section":"dataset","summary":"Does neonatal imitation exist? Insights from a meta-analysis of 336 effect sizes\n26 papers | 336 experiments | 949 subjects","tags":["cognitive_development"],"title":"Neonatal Imitation","type":"dataset"},{"authors":null,"categories":null,"content":" Online word recognition Frank, Lewis, \u0026amp; MacDonald (2016) N papers = 6, N experiments = 15, N participants = 366 Online word recognition of familiar words using two-alternative forced choice preferential looking. Curator is Molly Lewis Search Strategy: \"We conducted a systematic literature review by using Google Scholar to identify peer-reviewed papers citing Fernald et al. (1998). We screened this sample manually to find the subsample of 12 papers that reported both accuracy and reaction time with sufficient detail to permit coding.\" Systematic: no ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"76d31b2f4db975c078f1dca2393b20f3","permalink":"https://langcog.github.io/metalab/dataset/word_recognition/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/word_recognition/","section":"dataset","summary":"Online word recognition of familiar words using two-alternative forced choice preferential looking.\n6 papers | 15 experiments | 366 subjects","tags":["early_language"],"title":"Online word recognition","type":"dataset"},{"authors":null,"categories":null,"content":" Phonotactic learning Cristia (2018) N papers = 15, N experiments = 47, N participants = 890 Infants' ability to learn phonotactic generalizations from a short exposure. Curator is Alex Cristia Search Strategy: \"Studies were considered based on a forward search from a seminal paper on both pubmed and google search, a list of references produced by the author, direct contact of labs having published on the topic, and announcements to several mailing lists.\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cd01dacfd41b6617d68cfbce591ffe5b","permalink":"https://langcog.github.io/metalab/dataset/phonotactics/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/phonotactics/","section":"dataset","summary":"Infants' ability to learn phonotactic generalizations from a short exposure.\n15 papers | 47 experiments | 890 subjects","tags":["early_language"],"title":"Phonotactic learning","type":"dataset"},{"authors":null,"categories":null,"content":" Pointing and vocabulary (concurrent) Colonnesi et al. (2010) N papers = 12, N experiments = 12, N participants = 319 Concurrent correlations between pointing and vocabulary. Curator is Molly Lewis Search Strategy: \"The search method involved inspection of digital databases (Web of Knowledge, Picarta, PsychInfo) using the following keywords: pointing, gesture, declarative, imperative, precursors, language, words, vocabulary, infancy, intentional communication, and joint attention. Inspection of the reference section of relevant literature was an additional search method (ancestry method). Additionally, also unpublished sources were consulted, such as dissertations and presentations and studies under revision, by using Google Scholar, contacting researchers in the field and consulting digital databases of dissertations (e.g., PROQUEST). Three selection criteria were used to select studies: (a) measurement of infant production and/or comprehension of the pointing gesture; (b) measurement of language by assessing either receptive or expressive language; (c) report of a relation between pointing and language or the presence of data in the article allowing the calculation of a relation between pointing and language development. Exclusion criteria were: (a) subjects with mental or developmental disorders; (b) children older than 60 months; (c) studies in which the pointing gesture was not coded separately from other gestures.\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"295ab71d96fc79d35c38075796b3fbb9","permalink":"https://langcog.github.io/metalab/dataset/pointing_concurrent/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/pointing_concurrent/","section":"dataset","summary":"Concurrent correlations between pointing and vocabulary.\n12 papers | 12 experiments | 319 subjects","tags":["early_language"],"title":"Pointing and vocabulary (concurrent)","type":"dataset"},{"authors":null,"categories":null,"content":" Pointing and vocabulary (longitudinal) Colonnesi et al. (2010) N papers = 18, N experiments = 18, N participants = 558 Longitudinal correlations between pointing and later vocabulary. Curator is Molly Lewis Search Strategy: \"The search method involved inspection of digital databases (Web of Knowledge, Picarta, PsychInfo) using the following keywords: pointing, gesture, declarative, imperative, precursors, language, words, vocabulary, infancy, intentional communication, and joint attention. Inspection of the reference section of relevant literature was an additional search method (ancestry method). Additionally, also unpublished sources were consulted, such as dissertations and presentations and studies under revision, by using Google Scholar, contacting researchers in the field and consulting digital databases of dissertations (e.g., PROQUEST). Three selection criteria were used to select studies: (a) measurement of infant production and/or comprehension of the pointing gesture; (b) measurement of language by assessing either receptive or expressive language; (c) report of a relation between pointing and language or the presence of data in the article allowing the calculation of a relation between pointing and language development. Exclusion criteria were: (a) subjects with mental or developmental disorders; (b) children older than 60 months; (c) studies in which the pointing gesture was not coded separately from other gestures.\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"893fa3a6d4fdef2222a92dbe0ae7b406","permalink":"https://langcog.github.io/metalab/dataset/pointing_longitudinal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/pointing_longitudinal/","section":"dataset","summary":"Longitudinal correlations between pointing and later vocabulary.\n18 papers | 18 experiments | 558 subjects","tags":["early_language"],"title":"Pointing and vocabulary (longitudinal)","type":"dataset"},{"authors":null,"categories":null,"content":" Prosocial agents Margoni \u0026amp; Surian (2018) N papers = 26, N experiments = 61, N participants = 1244 Do infants prefer a prosocial agent over an antisocial agent? Curator is Francesco Margoni Search Strategy: PsychINFO + references of relevant papers + calls on mailing lists Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7ca17d536f7303538822b20fe0b31ebd","permalink":"https://langcog.github.io/metalab/dataset/prosocial/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/prosocial/","section":"dataset","summary":"Do infants prefer a prosocial agent over an antisocial agent?\n26 papers | 61 experiments | 1244 subjects","tags":["cognitive_development"],"title":"Prosocial agents","type":"dataset"},{"authors":null,"categories":null,"content":" Simple arithmetic competences Christodoulou et al. (2017) N papers = 6, N experiments = 14, N participants = 369 Do infants have simple arithmetic competences? Curator is Search Strategy: Seeded with Winn (1992) Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6c881f4f11b665e39fed96a8664e9cb9","permalink":"https://langcog.github.io/metalab/dataset/arithmetic/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/arithmetic/","section":"dataset","summary":"Do infants have simple arithmetic competences?\n6 papers | 14 experiments | 369 subjects","tags":["cognitive_development"],"title":"Simple arithmetic competences","type":"dataset"},{"authors":null,"categories":null,"content":" Sound symbolism Lammertink et al. (2016) N papers = 11, N experiments = 44, N participants = 425 Bias to assume a non-arbitrary relationship between form and meaning (\"bouba-kiki effect\") in forced-choice paradigms. Curator is Sho Tsuji Search Strategy: \"We followed the PRISMA statement (Moher, Liberati, Tetzlaff, Altmann, \u0026amp; The PRISMA Group, 2009) for selecting and reporting on the studies to be included in our meta-analysis. We decided to include articles if they were assessing the on-line processing of sound-symbolically matching or mismatching sound-shape correspondences related to the bouba-kiki effect (thus, testing both ‘round’ and ‘spiky’ correspondences) in children up to and inclusive of the age of 3 years. ‘Matching’ responses refer to children’s responses to congruent sound-shape associations (round word+round object; spiky word+spiky object) and ‘mismatching’ responses refer to children’s responses to incongruent sound-shape associations (round word+spiky shape; spiky word+round shape), respectively. Since we were already aware of 10 published articles, conference presentations or conference proceedings papers that fit our inclusion criteria,and since we considered our strict inclusion this criteria to lead to a rather small selection of articles, we chose a seed strategy rather than a broad literature search. We began by assembling 4 key articles that fit the inclusion criteria (Asano et al., 2015; Maurer, Pathman \u0026amp; Mondloch, 2006; Ozturk, Krehm \u0026amp; Vouloumanos, 2012; Spector \u0026amp; Maurer, 2013) as well as two recent review papers on sound symbolism including infancy (Imai \u0026amp; Kita, 2014; Lockwood \u0026amp; Dingemanse, 2015). For all of these articles, we screened all potentially relevant references cited in these articles as well as references citing these articles and ‘related articles’ on their title and abstracts on scholar.google.com. Additionally, we screened titles and abstracts of all articles that cited one of the 4 key articles mentioned above (Asano et al. 2015: 16 citations; Maurer et al. 2006: 241 citations; Ozturk et al. 2012: 54 citations and Spector and Maurer, 2013: 9 citations). This search did not lead to additional eligible articles. In addition, we were aware of 9 conference presentations or conference proceedings papers that fit our inclusion criteria and were not redundant with one of our seed articles, including three by the two first authors of the present article.\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cad055c7933b317a4259bbd086063a4b","permalink":"https://langcog.github.io/metalab/dataset/symbolism/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/symbolism/","section":"dataset","summary":"Bias to assume a non-arbitrary relationship between form and meaning (\"bouba-kiki effect\") in forced-choice paradigms.\n11 papers | 44 experiments | 425 subjects","tags":["early_language"],"title":"Sound symbolism","type":"dataset"},{"authors":null,"categories":null,"content":" Statistical sound category learning Cristia (2018) N papers = 11, N experiments = 20, N participants = 634 Infants' ability to learn sound categories from their acoustic distribution. Curator is Alex Cristia Search Strategy: \"Studies were considered based on a forward search from a seminal paper on both pubmed and google search, a list of references produced by the author, manual inspection of several editions of two leading conferences (ISIS and IASCL 2004-2012), direct contact of labs having published on the topic, and announcements to several mailing lists.\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9d0d6eafb846aa47a1f79419b485ac8b","permalink":"https://langcog.github.io/metalab/dataset/sounds/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/sounds/","section":"dataset","summary":"Infants' ability to learn sound categories from their acoustic distribution.\n11 papers | 20 experiments | 634 subjects","tags":["early_language"],"title":"Statistical sound category learning","type":"dataset"},{"authors":null,"categories":null,"content":" Statistical word segmentation Black \u0026amp; Bergmann (2017) N papers = 31, N experiments = 103, N participants = 1546 Can infants segment words from artificial mini-languages based on syllable-level statistics? Curator is Christina Bergmann Search Strategy: \"Expert list and strategic scholar search papers citing Saffran, Aslin, \u0026amp; Newport (1996) with infant/infancy, but not visual in the title. Second search with month/s and not infant/infancy or visual\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"68de6d91435e8517652057afd4dcf8ae","permalink":"https://langcog.github.io/metalab/dataset/statseg/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/statseg/","section":"dataset","summary":"Can infants segment words from artificial mini-languages based on syllable-level statistics?\n31 papers | 103 experiments | 1546 subjects","tags":["early_language"],"title":"Statistical word segmentation","type":"dataset"},{"authors":null,"categories":null,"content":" Switch task Tsui et al. (2019) N papers = 47, N experiments = 143, N participants = 2764 Infant word learning in the switch task Curator is Angeline Tsui Search Strategy: Seeded with Stager \u0026amp; Werker et al. (1997) and Werker et al. (1998) in Google Scholar + manual search Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"061a4b9afa36be67401ace88ce9582ae","permalink":"https://langcog.github.io/metalab/dataset/switchtask/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/switchtask/","section":"dataset","summary":"Infant word learning in the switch task\n47 papers | 143 experiments | 2764 subjects","tags":["early_language"],"title":"Switch task","type":"dataset"},{"authors":null,"categories":null,"content":" Symbolic play Quinn \u0026amp; Kidd (2018) N papers = 31, N experiments = 196, N participants = 7011 Is there a relationship between symbolic play and language development? Curator is Search Strategy: database search Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f6a90f6707d6088f88fed94428f8521a","permalink":"https://langcog.github.io/metalab/dataset/play/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/play/","section":"dataset","summary":"Is there a relationship between symbolic play and language development?\n31 papers | 196 experiments | 7011 subjects","tags":["early_language"],"title":"Symbolic play","type":"dataset"},{"authors":null,"categories":null,"content":" Syntactic bootstrapping Cao \u0026amp; Lewis (in prep.) N papers = 18, N experiments = 60, N participants = 832 Whether infants can correctly identify the references of the novel verbs embedded in a syntactically informative context. Curator is Anjie Cao Search Strategy: We conducted our literature search following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses checklist (PRISMA; Moher et al., 2009). We identified relevant papers by conducting a keyword search in Google Scholar with the phrase \"Syntactic Bootstrapping\" and a forward search on papers that cited the seminal paper (Naigles, 1990). We screened the first 60 pages of the keyword search results and the first 10 pages of the forward search results. The screening processes ended because we could no longer identify relevant, non-duplicate papers from consecutive pages. Additional papers were identified by consulting the references section of the most recent literature review (Fisher, Jin, \u0026amp; Scott, 2020) and the experts in the field. In our final sample, we included published journal articles, conference proceedings, doctoral dissertations, and unpublished manuscripts. Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa8c6b5dc0be00809a53ccc20d6f5419","permalink":"https://langcog.github.io/metalab/dataset/synboot/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/synboot/","section":"dataset","summary":"Whether infants can correctly identify the references of the novel verbs embedded in a syntactically informative context.\n18 papers | 60 experiments | 832 subjects","tags":["early_language"],"title":"Syntactic bootstrapping","type":"dataset"},{"authors":null,"categories":null,"content":" Video deficit Strouse \u0026amp; Samson (2020) N papers = 69, N experiments = 122, N participants = 3004 Learning from video versus face to face presentation of similar content. Curator is Gabrielle Strouse Search Strategy: \"Our comprehensive, systematic search strategy included keyword searching, evaluation of references included in eligible articles and review articles, searching of conference proceedings, personal contact with authors working in the field, and hand searching of any journals that included four or more eligible studies. Search terms included the exact phrase, “video deficit,” or combinations of: (video, television, dvd, tv, program*, educational media, baby media) AND (children, preschoolers, toddlers, infants, babies) AND (learn*, understand*). To provide coverage of all four major disciplines relevant to this area of research and its relevant grey literature, we first searched PsycInfo, Communication Abstracts, Communication and Mass Media Complete, ERIC, Medline, and Google Scholar. We then searched the reference lists of review articles and eligible articles identified through these searches. Next we searched conference proceedings of the Society for Research in Child Development and the International Conference on Infant Studies (note that Communication and Mass Media Complete, ERIC, and Google Scholar also index conference proceedings, which were included in the initial search). Finally, we contacted authors and searched journals that occurred more than four times in our list of eligible reports. \" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"82e25222f45caba19862f6567ed546b7","permalink":"https://langcog.github.io/metalab/dataset/videodef/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/videodef/","section":"dataset","summary":"Learning from video versus face to face presentation of similar content.\n69 papers | 122 experiments | 3004 subjects","tags":["cognitive_development"],"title":"Video deficit","type":"dataset"},{"authors":null,"categories":null,"content":" Vowel discrimination (native) Tsuji \u0026amp; Cristia (2014) N papers = 33, N experiments = 145, N participants = 2491 Discrimination of native-language vowels, including results from a variety of methods. Curator is Sho Tsuji Search Strategy: \"A full search on scholar.google.com was conducted in September 2012 with the keyword combination “{infant|infancy} \u0026amp; {vowel|speech sound|syllable} \u0026amp; discrimination.” Additionally, the search terms were translated into French, German, Japanese, and Spanish for additional searches. We also asked experts in the field to inform us of any published or unpublished studies we had missed. Experts were defined as scientists having participated in at least two studies identified in our intermediate search sample or who were part of a lab where such research had taken place, and who were still active in the field or could be otherwise contacted. Further, articles were added based on a screening of articles cited and articles citing the articles in the remaining search sample. The complete sample is available as a public resource (Tsuji \u0026amp; Cristia, in preparation, https://sites.google.com/site/inphondb/). The search sample was then narrowed down to the final search sample of 19 articles.\" (See paper for additional details) Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0b4d4680071601eb29a0c318341c8145","permalink":"https://langcog.github.io/metalab/dataset/inphondb-native/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/inphondb-native/","section":"dataset","summary":"Discrimination of native-language vowels, including results from a variety of methods.\n33 papers | 145 experiments | 2491 subjects","tags":["early_language"],"title":"Vowel discrimination (native)","type":"dataset"},{"authors":null,"categories":null,"content":" Vowel discrimination (non-native) Tsuji \u0026amp; Cristia (2014) N papers = 15, N experiments = 49, N participants = 573 Discrimination of non-native vowels, including results from a variety of methods. Curator is Sho Tsuji Search Strategy: See Native Vowel Discrimination, above. Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a9bcfe70167860e5a0e9b1cca7f71c61","permalink":"https://langcog.github.io/metalab/dataset/inphondb-nonnative/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/inphondb-nonnative/","section":"dataset","summary":"Discrimination of non-native vowels, including results from a variety of methods.\n15 papers | 49 experiments | 573 subjects","tags":["early_language"],"title":"Vowel discrimination (non-native)","type":"dataset"},{"authors":null,"categories":null,"content":" Word segmentation (behavioral) Bergmann \u0026amp; Cristia (2016) N papers = 69, N experiments = 299, N participants = 5699 Recognition of familiarized content or non-words from running, natural speech using behavioral methods. Curator is Christina Bergmann Search Strategy: \"We first generated a list of potentially relevant items to be included in our meta-analysis using the Google Scholar search engine, with the broad search term ‘infant word segmentation’ (following Gehanno, Rollin \u0026amp; Darmoni, 2013). This search was carried out on 27 November 2012 and we inspected the first 1000 results. Fifteen additional items were included based on recommendations and by scanning references of included papers. After removing duplicates, we screened the title and abstract of each remaining item and identified 231 items for full-text inspection using the following inclusion criteria: (1) original data were reported; (2) the stimulus material was continuous natural speech spoken in the participants’ native language; (3) the dependent measure was looking time (LT) at a neutral visual target (i.e. not a possible referent of one set of stimuli); (4) infants were normally developing.\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"50ac1723c40243cd98e684b5202f3be0","permalink":"https://langcog.github.io/metalab/dataset/inworddb/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/inworddb/","section":"dataset","summary":"Recognition of familiarized content or non-words from running, natural speech using behavioral methods.\n69 papers | 299 experiments | 5699 subjects","tags":["early_language"],"title":"Word segmentation (behavioral)","type":"dataset"},{"authors":null,"categories":null,"content":" Word segmentation (neuro) Vissers \u0026amp; Bergmann (unpublished) N papers = 1, N experiments = 6, N participants = 69 Infants’ recognition of familiarized content from running natural speech using brain measures Curator is Fleur Vissers Search Strategy: \" A search on the search term ‘word segmentation infants ERP’ in Google Scholar carried out on 1 October 2018 resulted in 1030 results. Of the first 110 results titles and abstract were screened. An additional search on 15 October 2018 on the search term ‘word segmentation infants NIRS’ resulted in 117 items. In addition, experts were asked for additional articles, resulting in 13 items. All of these items (240 items) were screened on their titles and abstracts. Twenty-one of these items were included and full-text inspection was done using the following inclusion criteria; (1) the participants were infants and were normally developing; (2) The method that was used was EEG or NIRS (Near-InfraRed Spectroscopy); (3) the stimuli material was continuous natural speech spoken in the infants’ native language. Studies reporting on rule learning, word-object mapping, or artificial grammar were excluded. Inspection of full-text resulted in the inclusion of 12 items.\" Systematic: yes ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"70f12323794f98e110bb85248bcd88b2","permalink":"https://langcog.github.io/metalab/dataset/wsnm/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/dataset/wsnm/","section":"dataset","summary":"Infants’ recognition of familiarized content from running natural speech using brain measures\n1 papers | 6 experiments | 69 subjects","tags":["early_language"],"title":"Word segmentation (neuro)","type":"dataset"}]